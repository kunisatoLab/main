<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>強化学習モデル: 最尤推定</title>

<script src="site_libs/header-attrs-2.12/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link rel="apple-touch-icon" type="image/png" href="apple-touch-icon-180x180.png">
<link rel="icon" type="image/png" href="icon-192x192.png">


<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>






<link rel="stylesheet" href="site_style.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Computational Clinical Psychology Lab</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="research.html">Research</a>
</li>
<li>
  <a href="team.html">Team</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Publications
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="book.html">書籍</a>
    </li>
    <li>
      <a href="articles.html">学術論文</a>
    </li>
    <li>
      <a href="articles-japanese.html">学術論文（日本語）</a>
    </li>
    <li>
      <a href="bulletin.html">紀要論文</a>
    </li>
    <li>
      <a href="presentation.html">国際会議発表</a>
    </li>
    <li>
      <a href="presentation-japanese.html">国内学会・研究会発表</a>
    </li>
  </ul>
</li>
<li>
  <a href="research-module.html">Research Module</a>
</li>
<li>
  <a href="education.html">Education</a>
</li>
<li>
  <a href="news.html">News</a>
</li>
<li>
  <a href="https://kunisatolab.github.io/english/index.html">English</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">強化学習モデル: 最尤推定</h1>

</div>


<div id="認知モデリングの推奨実践法" class="section level2">
<h2>認知モデリングの推奨実践法</h2>
<p>Busemeyer &amp; Diederich(2010), Heathcote (2015), Palminteri et
al.(2017)を参考に，認知モデリングの推奨実践法をまとめると，以下のようになります。</p>
<ul>
<li>A 認知課題と認知モデルを準備</li>
<li>B
人工データ生成とパラメータリカバリーを確認（モデルや課題の修正）</li>
<li>C データ収集と行動データを確認</li>
<li>D パラメータ推定</li>
<li>E 相対モデル比較</li>
<li>F モデル・シミュレーションと選択的影響テスト</li>
</ul>
<p>以降は，上記に従って進めていきます。</p>
<div id="使用するrパッケージ" class="section level3">
<h3>使用するRパッケージ</h3>
<p>以降で使用するRパッケージは以下になります。</p>
<pre class="r"><code>rm(list = ls())
library(tidyverse)
library(fields)
library(pso)</code></pre>
</div>
</div>
<div id="a-認知課題と認知モデルを準備" class="section level2">
<h2>A 認知課題と認知モデルを準備</h2>
<div id="逆転学習課題" class="section level3">
<h3>逆転学習課題</h3>
<p>逆転学習課題は以下のような課題です。</p>
<ul>
<li><p>Cools et
al.(2001)：合計80試行（前半40試行，後半逆転して40試行），フィードバックは顔（ポジティブが緑の嬉しい顔，ネガティブが赤の悲しい顔)，報酬:罰比は，80:20。</p></li>
<li><p>Cools et
al.(2002)を参考に，選択刺激の呈示位置は左右，刺激の選択画面は2000ms呈示されて（2000msを超えると遅いことを伝える「2秒以内に選択してください」），フィードバックは２つの刺激の間に500ms呈示。</p></li>
<li><p>den Ouden et
al.(2013)を参考に，選択はマウスでクリックする，80試行は疑似ランダム化された事前に決めた順番で提示する，参加者には変化する正答刺激を特定するように教示する。</p></li>
<li><p>Waegeman et
al.(2014)を参考に，最大2000ms選択画面を呈示する（押したら次に進む），選択した刺激を枠で囲って500ms呈示し，フィードバックを500ms呈示し，500ms-1500ms固視点(+)を呈示する。</p></li>
</ul>
<p>この逆転学習課題をjsPsychで作る方法は，<a
href="https://kunisatolab.github.io/main/how-to-jspsych3.html">jsPsychを用いた認知課題の作成3：確率的逆転学習課題</a>にあります。</p>
<div id="逆転学習課題の構造の確認" class="section level4">
<h4>逆転学習課題の構造の確認</h4>
<p>s1は，前半40試行において20％の確率で報酬のフィードバックがなされ，後半40試行で80%の確率でフィードバックがなされます（s2はその逆になる）。prob_s1とprob_s2に確率を設定して，reward_s1とreward_s2でランダムに80%や20%の確率で報酬が出てくるのを設定します。なお，報酬は１，罰は０としています。</p>
<pre class="r"><code>sim_data &lt;- tibble(trial = 1:80,
                   prob_s1 = rep(c(0.2, 0.8), each = 40),
                   prob_s2 = rep(c(0.8, 0.2), each = 40),
                   reward_s1 = ifelse(runif(80) &lt; prob_s1, 1, 0),
                   reward_s2 = ifelse(runif(80) &lt; prob_s2, 1, 0))</code></pre>
<p>プロットして確認します。黒実線は，s1の報酬FB確率で，青色がs1のフィードバック，赤色がs2のフィードバックになります。</p>
<pre class="r"><code>sim_data %&gt;% 
  ggplot(aes(x = trial, y = prob_s1)) +
  geom_line() +
  geom_point(aes(x = trial, y = reward_s1),colour = &#39;blue&#39;) +
  geom_point(aes(x = trial, y = reward_s2),colour = &#39;red&#39;)</code></pre>
<p><img src="how-to-cognitive-modeling-rl1_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
</div>
</div>
<div id="強化学習モデルq-learningモデル" class="section level3">
<h3>強化学習モデル(Q learningモデル)</h3>
<ul>
<li>Q learningモデルにおける更新式は以下の通りになります。</li>
</ul>
<p><span class="math display">\[
Q\left(s_{t}, a_{t}\right) \leftarrow Q\left(s_{t},
a_{t}\right)+\alpha\left(r_{t+1}+\gamma \max _{a} Q\left(s_{t+1},
a\right)-Q\left(s_{t}, a_{t}\right)\right)
\]</span></p>
<ul>
<li>今回の逆転学習課題の場合は，状態が1つの特殊なQ
learningになります。γのついた項は不要になり，報酬も選択した時点の報酬で更新します。</li>
</ul>
<p><span class="math display">\[
Q\left(s_{t}, a_{t}\right) \leftarrow Q\left(s_{t},
a_{t}\right)+\alpha\left(r_{t}-Q\left(s_{t}, a_{t}\right)\right)
\]</span></p>
<ul>
<li>Qlearningでは，学習した価値を元にして，選択肢を選びます（方策）。</li>
</ul>
<p>→多くの場合、基本的には価値の高い選択を選びますが，時に価値の高くない方も選択します（探索をする）。</p>
<p>→ここでは，以下のソフトマックス行動選択を方策に採用します。</p>
<ul>
<li>ソフトマックス行動選択とは，行動価値関数(Q)を用いて，確率分布（ボルツマン分布）を作ることで方策とする方法です。</li>
</ul>
<p>→　ざっくり言うと，特定の行動(i)のQ値を，全ての行動(1…m)のQ値の合計で割っている。その際に，Q値にベータをかけて，指数関数にいれています。</p>
<ul>
<li>ソフトマックス行動選択は，逆温度(inverse
temperature)βで，探索と利用のバランスをとります。β=0でランダム法，βが大きくなるとグリーディ法に近づきます。</li>
</ul>
<p><span class="math display">\[
P\left(a_{i} \mid s\right)=\frac{\exp \left[\beta Q\left(s,
a_{i}\right)\right]}{\sum_{j=1}^{m} \exp \left[\beta Q\left(s,
a_{j}\right)\right]}
\]</span></p>
<ul>
<li><p>もし選択肢が２つの場合は以下のように書けます（今回は状態もかわらないので，sやaも省略しています）。選択肢AとBがあった場合，Aを選択する確率は,指数関数（β×Aの価値）を{指数関数（β×Aの価値）＋指数関数（β×Bの価値）}で割ったものになります。</p></li>
<li><p>βは0に近づくほど、選択確率は0.5に近づきます（価値の差が選択に反映されなくなります）</p></li>
</ul>
<p><span class="math display">\[
P(A)=\frac{\exp(\beta Q_{A})}{\exp(\beta Q_{A}) + \exp(\beta Q_{B})}
\]</span></p>
<div id="q-learningの関数" class="section level4">
<h4>Q learningの関数</h4>
<p>上記のQ learningの計算を関数にすると以下のようになります。</p>
<pre class="r"><code>q_learning_sim &lt;- function(alpha, beta,data) {
  #変数の準備
  value_s1 &lt;- 0          # s1の価値(初期値は0)
  value_s2 &lt;- 0          # s2の価値(初期値は0)
  current_choice &lt;- NULL     # ある時点の選択（1=s1，0=s2）
  choice_prob_s1 &lt;- NULL  # s1の選択確率
  reward &lt;- NULL                 # 報酬
  # Qlearningモデル
  for (i in 1:nrow(data)){
    # s1を選ぶ確率を計算し,一様分布から発生させた乱数が行動選択確率よりも小さい時に1（s1），大きい時に0（s2）
    choice_prob_s1[i] &lt;- exp(beta*value_s1[i])/(exp(beta*value_s1[i])+exp(beta*value_s2[i]))
    current_choice[i] &lt;- as.integer(runif(1,min=0,max=1) &lt;= choice_prob_s1[i])
    #FBを報酬(r)として、価値の更新を行う。
    if (current_choice[i] == 1){
        reward[i] &lt;- data$reward_s1[i]
        #予測誤差の計算
        prediction_error &lt;-  reward[i] - value_s1[i]
        #予測誤差を使ってs1の価値を更新する
        value_s1[i+1] &lt;- value_s1[i]+alpha*prediction_error
        #s2は更新なし
        value_s2[i+1] &lt;- value_s2[i]
    }else{
        reward[i] &lt;- data$reward_s2[i]
        #予測誤差の計算
        prediction_error &lt;- reward[i] - value_s2[i]
        #予測誤差を使ってs2の価値を更新する
        value_s2[i+1] &lt;- value_s2[i]+alpha*prediction_error
        #s1は更新なし
        value_s1[i+1] &lt;- value_s1[i]
    }
  }
  result &lt;- data.frame(trial = data$trial,
              value_s1 = value_s1[1:nrow(data)], 
              value_s2 = value_s2[1:nrow(data)], 
              prob_s1 = choice_prob_s1,
              choice = current_choice,
              reward = reward)
  return(result)
}</code></pre>
</div>
<div id="q-learningの関数の動作確認" class="section level4">
<h4>Q learningの関数の動作確認</h4>
<p>α，β，各施行の報酬の有無(入力刺激)がはいったデータを指定すればQ
leaningを試すことができます（とりあえず，ここでは，プロットして，動作するかだけ確認しましょう）。</p>
<pre class="r"><code>result &lt;- q_learning_sim(alpha = 0.5, beta = 5,data = sim_data) 
result %&gt;% 
  ggplot(aes(x = trial, y = value_s1)) +
  geom_line() + 
  geom_line(aes(x = trial, y = prob_s1),linetype=&quot;dashed&quot;) +
  geom_point(aes(x = trial, y = choice)) +
  geom_point(aes(x = trial, y = reward), colour = &#39;red&#39;) </code></pre>
<p><img src="how-to-cognitive-modeling-rl1_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>おお，なんか人間っぽいというか知性がある感じがしますね！</p>
</div>
</div>
</div>
<div id="b-人工データ生成とパラメータリカバリーを確認モデルや課題の修正"
class="section level2">
<h2>B
人工データ生成とパラメータリカバリーを確認（モデルや課題の修正）</h2>
<div id="人工データの生成" class="section level3">
<h3>人工データの生成</h3>
<p>Q
learningモデルとソフトマックス行動選択を用いて，個々の参加者のパラメータ推定を行うのが最終的な目標になります。すぐにリアルデータの推定をしたくなりますが，まずはシミュレーション(人工データ生成)から始めます。モデルとパラメータと実験状況（刺激の種類やFBの確率など）を準備して，データを生成してみましょう。その際に，αをβを色々と変更させて，生成されるデータの挙動も確認しましょう！上記で作成したq_learning_sim関数を使えば，以下のようにαをβを色々と変更したときのデータの挙動が確認できます。</p>
<pre class="r"><code>result &lt;- q_learning_sim(alpha = 0.3, beta = 1,data = sim_data) 
result %&gt;% 
  ggplot(aes(x = trial, y = value_s1)) +
  geom_line() + 
  geom_line(aes(x = trial, y = prob_s1),linetype=&quot;dashed&quot;) +
  geom_point(aes(x = trial, y = choice)) +
  geom_point(aes(x = trial, y = reward), colour = &#39;red&#39;) </code></pre>
<p><img src="how-to-cognitive-modeling-rl1_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<div id="演習" class="section level4">
<h4>演習</h4>
<ul>
<li>S2の価値と選択確率もプロットしてみよう！</li>
</ul>
</div>
</div>
<div id="シミュレーションデータを用いてパラメータリカバリーを行う"
class="section level3">
<h3>シミュレーションデータを用いてパラメータリカバリーを行う</h3>
<div id="パラメータ推定の手順" class="section level4">
<h4>パラメータ推定の手順</h4>
<p>パラメータ推定の手順は以下になります。</p>
<ol style="list-style-type: decimal">
<li>パラメータを含むモデルを設定</li>
<li>パラメータを評価する基準を設定</li>
<li>最良の評価を与えるパラメータを決定する</li>
</ol>
<ul>
<li>1.パラメータを含むモデルを設定</li>
</ul>
<p>→ Q learning model,
方策はソフトマックス行動選択ルールを仮定します（なお，仮定というが重要で，これが真実のモデルは全く無くて，可能性のあるモデルの１つであるという点は意識しておく必要があります）。</p>
<ul>
<li>2.パラメータを評価する基準を設定</li>
</ul>
<p>→
モデルとパラメータが与えられた時の観察されたデータの尤もらしさ（尤度:
Likekihood）を評価基準にします。尤度が高いほど，そのモデル（パラメータ）の仮定は尤もらしいと考えられます。尤度は，実際に選んだ選択肢の行動選択確率を全ての試行でかけ合わせたもの（総積）です。モデルが考えた選択確率がどれくらい実際のデータにフィットしているか調べています。</p>
<p><span class="math display">\[
\text {Likelihood}=\prod_{t=1}^{T} P\left(a_{t}\right)
\]</span>
尤度を対数化した対数尤度を使うことが多いです。試行ごとに確率をかけていくと桁が小さくなりすぎるので，対数をとっておきます（例
0.00000000001は対数をとると-25.32844です）。</p>
<p><span class="math display">\[
\text { LogLikelihood }=\log \left(\prod_{t=1}^{T}
P\left(a_{t}\right)\right)
\]</span></p>
<p>確率の総積は，桁が小さくなりすぎて計算上の不都合があるので（桁落ちがある），対数化した上で，総和を求めるのが良いです（log(A*B)=log(A)+log(B)という公式があります）。</p>
<p><span class="math display">\[
\text {LogLikelihood}=\sum_{i=1}^{T} \log
\left(P\left(a_{t}\right)\right)
\]</span></p>
<p>さて，対数尤度を計算してみましょう！q_learning_simを少し改変して，q_learning_ll関数を作ります。選択確率から選択を生成する部分を削除して，対数尤度の計算をいれたのが大きな変更点です。</p>
<pre class="r"><code>q_learning_ll &lt;- function(alpha, beta,data) {
  #変数の準備
  value_s1 &lt;- 0          # s1の価値(初期値は0)
  value_s2 &lt;- 0          # s2の価値(初期値は0)
  prob_s1 &lt;- NULL  # s1の選択確率
  ll &lt;- 0                 # 対数尤度
  # Qlearningモデル
  for (i in 1:nrow(data)){
    # s1を選ぶ確率を計算
    prob_s1[i] &lt;- exp(beta*value_s1[i])/(exp(beta*value_s1[i])+exp(beta*value_s2[i]))
    #FBを報酬(r)として、価値の更新を行う。
    if (data$choice[i] == 1){
        #予測誤差の計算
        prediction_error &lt;-  data$reward[i] - value_s1[i]
        #予測誤差を使ってs1の価値を更新する
        value_s1[i+1] &lt;- value_s1[i]+alpha*prediction_error
        #s2は更新なし
        value_s2[i+1] &lt;- value_s2[i]
        # 対数尤度の計算のために選択したs1を選ぶ確率の対数を加算
        ll &lt;- ll + log(prob_s1[i])
    }else{
        #予測誤差の計算
        prediction_error &lt;- data$reward[i] - value_s2[i]
        #予測誤差を使ってs2の価値を更新する
        value_s2[i+1] &lt;- value_s2[i]+alpha*prediction_error
        #s1は更新なし
        value_s1[i+1] &lt;- value_s1[i]
        # 対数尤度の計算のために選択したs2を選ぶ確率の対数を加算
        ll &lt;- ll + log(1-prob_s1[i])
    }
  }
  result &lt;- data.frame(trial = data$trial,
              value_s1 = value_s1[1:nrow(data)], 
              value_s2 = value_s2[1:nrow(data)], 
              prob_s1 = prob_s1,
              choice = data$choice,
              reward = data$reward)
  return(list(result = result, ll = ll))
}</code></pre>
<p>q_learning_simを使って，データ（選択）を生成して，dataに格納します。そして，それを使って，同じαとβの値の時の尤度を計算してみます。</p>
<pre class="r"><code>data &lt;- q_learning_sim(alpha = 0.2, beta = 5,data = sim_data) 
result &lt;- q_learning_ll(alpha = 0.2, beta = 5,data = data) 
result$ll</code></pre>
<pre><code>## [1] -21.32361</code></pre>
<p>alpha = 0.2, beta = 5で生成されたデータにたいして，alpha = 0.6, beta
=
1の時の尤度を計算します。尤度が小さくなったかと思います。他にもαとβを変更して（生成時の値alpha
= 0.2, beta =
5に近づけたり，遠ざけたりする），尤度の挙動を確認してみましょう。</p>
<pre class="r"><code>result &lt;- q_learning_ll(alpha = 0.6, beta = 1,data = data) 
result$ll</code></pre>
<pre><code>## [1] -38.75351</code></pre>
<ul>
<li>3.最良の評価を与えるパラメータを決定する</li>
</ul>
<p>→最も尤度が高くなるパラメータを探す（最適化）。最尤推定，ベイズ推定など色々な方法があるが，ここでは，単純なグリッドサーチを用いた最尤推定を行う。</p>
</div>
<div id="パラメータリカバリーグリッドサーチ定" class="section level4">
<h4>パラメータリカバリー（グリッドサーチ定）</h4>
<ul>
<li>グリッドサーチは，可能性のあるパラメータの組み合わせを格子状にして，順番に尤度を評価する方法です。指定したパラメータの範囲内で最も高い尤度のパラメータを選択します（最尤推定法：maximum
likelihood estimate）</li>
<li>グリッドは研究者が決めます。今回は，αは0から１まで0.01刻みでサーチし(101個の値)，βは0から15まで0.2刻みでサーチする(76個の値)ことにします(つまり7676個のパラメータの組み合わせで尤度を評価します)。</li>
</ul>
</div>
<div id="グリッドサーチ用関数" class="section level4">
<h4>グリッドサーチ用関数</h4>
<p>さて，グリッドサーチをするgrid_search関数を作成します。引数は，選択（choice），報酬(reward)の入ったデータになります。αは0から１まで0.01刻みでサーチし(101個)、βは0から15まで0.2刻みでサーチする(76個)。αとβの組み合わせで，7676個のパラメータの組み合わせを探索する。３次元プロットしたいので，行がbeta，列がalphaで尤度を保存していったstore_3dも作成しています。</p>
<pre class="r"><code>grid_search &lt;- function(data) {
  #　値を保存する変数の設定
  store_alpha &lt;- NULL　#サーチしたαの保存
  store_beta &lt;- NULL　 #サーチしたβの保存
  store_loglike &lt;- NULL　#計算した対数尤度の保存
  store_3d &lt;- NULL　#３次元プロット用
  store_ll &lt;- NULL　#store3Dの途中計算用に別途対数尤度を用意する
  # グリッドサーチの実施
  beta &lt;- 0
  for(m in 1:76){
    alpha &lt;- 0
    for(n in 1:101){
        result &lt;- q_learning_ll(alpha, beta,data)
        store_alpha[(m-1)*101+n] &lt;- alpha
        store_beta[(m-1)*101+n] &lt;- beta
        store_loglike[(m-1)*101+n] &lt;- result$ll
        store_ll[n] &lt;- result$ll
        # alpheを0.01刻みで増やす
        alpha &lt;- alpha + 0.01
    }  
    store_3d &lt;- rbind(store_3d,store_ll)
    #betaを0.2刻みで増やす
    beta　&lt;- beta +0.2
  }
    calc_results&lt;- tibble(store_alpha, store_beta, store_loglike)
    return(list(calc_results = calc_results, store_3d = store_3d))
}</code></pre>
</div>
<div id="最尤推定グリッドサーチの実施" class="section level4">
<h4>最尤推定（グリッドサーチ）の実施</h4>
<p>grid_search関数を使って，最尤推定値を探します。まず，alpha=0.3,beta=5に設定したq_learning_sim関数でデータを作ります。そして，grid_search関数に作ったdataをいれてグリッドサーチをさせます。ちょっと時間がかかります。</p>
<pre class="r"><code>data &lt;- q_learning_sim(alpha = 0.3, beta = 5,data = sim_data) 
grid_result &lt;- grid_search(data)</code></pre>
</div>
<div id="次元データのプロット" class="section level4">
<h4>３次元データのプロット</h4>
<p>αとβと尤度の３次元データをプロットしてみます。データ生成時に設定したパラメータの値周辺になっているでしょうか？</p>
<pre class="r"><code>rownames(grid_result$store_3d) &lt;- NULL
alpha &lt;- seq(0,1,0.01)
beta &lt;- seq(0,15,0.2)
image.plot(beta,alpha,grid_result$store_3d)</code></pre>
<p><img src="how-to-cognitive-modeling-rl1_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
</div>
<div id="周辺尤度" class="section level4">
<h4>周辺尤度</h4>
<p>3Dプロットだとちょっと判断が難しいので，周辺尤度を求めてみます。例えば，βがどのような値をとるかにかかわらないαの尤度が，αの周辺尤度です。つまり，αの値ごとに，平均尤度を計算する感じです（βも同様です）。</p>
<pre class="r"><code>#対数尤度を尤度へ
matrix_ll &lt;- exp(grid_result$store_3d)
# 行（beta）ごとに平均をして、全体の平均で標準化
beta_sum_ll &lt;- rowSums(matrix_ll)
beta_marginal_like &lt;- beta_sum_ll/sum(beta_sum_ll)
beta_marginal_like_data &lt;- data.frame(beta,beta_marginal_like)
colnames(beta_marginal_like_data) &lt;- c(&quot;parameter&quot;,&quot;marginal_like&quot;)
# 列（alpha）ごとに平均をして、全体の平均で標準化
alpha_sum_ll &lt;- colSums(matrix_ll)
alpha_marginal_like &lt;- alpha_sum_ll/sum(alpha_sum_ll)
alpha_marginal_like_data &lt;- data.frame(alpha,alpha_marginal_like)
colnames(alpha_marginal_like_data) &lt;- c(&quot;parameter&quot;,&quot;marginal_like&quot;)
#プロット
beta_marginal_like_data %&gt;% 
  ggplot(aes( x = parameter, y = marginal_like)) +
  geom_line() +
  labs(x=&quot;Parameter β&quot;, y=&quot;p(data|model)&quot;)</code></pre>
<p><img src="how-to-cognitive-modeling-rl1_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<pre class="r"><code>alpha_marginal_like_data %&gt;% 
  ggplot(aes( x = parameter, y = marginal_like)) +
  geom_line() +
  labs(x=&quot;Parameter α&quot;, y=&quot;p(data|model)&quot;)</code></pre>
<p><img src="how-to-cognitive-modeling-rl1_files/figure-html/unnamed-chunk-13-2.png" width="672" /></p>
</div>
<div id="最尤推定値とパラメータリカバリのチェック"
class="section level4">
<h4>最尤推定値とパラメータリカバリのチェック</h4>
<p>最も対数尤度が高いパラメータの値を選択するのが最尤推定法です。which.maxで最も対数尤度の高いパラメータの値をとってきましょう。α=0.3，β=5で作ったデータなので，パラメータリカバリできているか確認しましょう。なお，もともとのデータ生成の部分で確率的な変動が入るので，ある程度誤差がはいります。一致するかというよりは，大幅にずれてないかチェックします。</p>
<pre class="r"><code># 最尤推定値
maxIndex &lt;- which.max(grid_result$calc_results$store_loglike)
paste(&quot;最尤推定値: α =&quot;,grid_result$calc_results$store_alpha[maxIndex],
      &quot;β =&quot;,grid_result$calc_results$store_beta[maxIndex], 
      &quot;,対数尤度: Log Likelihood = &quot;,grid_result$calc_results$store_loglike[maxIndex])</code></pre>
<pre><code>## [1] &quot;最尤推定値: α = 0.36 β = 4.4 ,対数尤度: Log Likelihood =  -26.5071942804073&quot;</code></pre>
</div>
<div id="価値と行動選択確率のプロットモデルシミュレーション"
class="section level4">
<h4>価値と行動選択確率のプロット（モデル・シミュレーション）</h4>
<ul>
<li><p>与えられたモデルがデータを生成する能力のことを生成パフォーマンスと言います（Palminteri
et al.,
2017）。この生成パフォーマンスを検討するには，パラメータ推定によって最もフィットしたパラメータ値と認知モデルを用いてデータ生成を行って，実際の行動レベルでの効果が検出できるのかを検討するモデル・シミュレーションが必要です（Palminteri
et al., 2017）。</p></li>
<li><p>さっそくグリッドサーチによって推定された最尤推定値を
q_learning_sim()に投入して，データ生成をしてみましょう。そして，今回生成されたデータ（選択反応）と最初のデータをまとめたデータセットを作りましょう。</p></li>
</ul>
<pre class="r"><code># グリードサーチで推定された最尤推定値を使ってデータを生成する。
sim_estimated &lt;- q_learning_sim(grid_result$calc_results$store_alpha[maxIndex],
                                 grid_result$calc_results$store_beta[maxIndex],sim_data)
data_original_estimated &lt;- tibble(trial = data$trial,
                                  choice_original = data$choice,
                                  choice_estimated = sim_estimated$choice)</code></pre>
<ul>
<li>青い点がデータ，赤い点が最尤推定値から生成したデータです(見やすくなるように少しずらしました)。２つは重なっているでしょうか？</li>
</ul>
<pre class="r"><code>data_original_estimated %&gt;% 
  mutate(choice_original_plot = choice_original +0.02) %&gt;% 
  ggplot(aes(x = trial, y = choice_original_plot)) +
  geom_point(colour = &quot;blue&quot;) +
  geom_point(aes(x = trial, y = choice_estimated),colour = &quot;red&quot;)</code></pre>
<p><img src="how-to-cognitive-modeling-rl1_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<ul>
<li>以下のように，クロス集計して確認することもできます。</li>
</ul>
<pre class="r"><code>table(data_original_estimated$choice_original,data_original_estimated$choice_estimated)</code></pre>
<pre><code>##    
##      0  1
##   0 31 10
##   1 11 28</code></pre>
</div>
</div>
</div>
<div id="c-データ収集と行動データを確認" class="section level2">
<h2>C データ収集と行動データを確認</h2>
<p>では，実験をおこなって，行動データを収集したことにしましょう。以下では，国里が用意した模擬データを使って解析を行います。以下を実行して，データをダウンロードください。</p>
<pre><code>temp &lt;- tempfile()
download.file(&quot;https://github.com/kunisatoLab/main/raw/master/materials/data.zip&quot;,temp)
unzip(temp)
unlink(temp)</code></pre>
<div id="データの確認" class="section level3">
<h3>データの確認</h3>
<pre class="r"><code>#データフォルダをカレントディレクトリに設定して中のファイルの情報を取得する
setwd(&quot;data&quot;)
file_names &lt;- list.files()
file_names</code></pre>
<pre><code>## [1] &quot;sub01.csv&quot; &quot;sub02.csv&quot; &quot;sub03.csv&quot; &quot;sub04.csv&quot; &quot;sub05.csv&quot;</code></pre>
<div id="sub01のデータの確認" class="section level4">
<h4>sub01のデータの確認</h4>
<p>sub01.csvをread_csv()で読み込む</p>
<pre class="r"><code>sub01 &lt;- read_csv(&quot;data/sub01.csv&quot;)</code></pre>
<pre><code>## Rows: 325 Columns: 13
## ── Column specification ────────────────────────────────────────────────────────
## Delimiter: &quot;,&quot;
## chr (5): trial_type, internal_node_id, rt, stimulus, key_press
## dbl (7): trial_index, time_elapsed, button_pressed, left_right_s1, left_righ...
## lgl (1): success
## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
<pre class="r"><code>sub01</code></pre>
<pre><code>## # A tibble: 325 × 13
##    trial_type trial_index time_elapsed internal_node_id rt    stimulus key_press
##    &lt;chr&gt;            &lt;dbl&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;    
##  1 pavlovia             0            3 0.0-0.0          &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;     
##  2 html-keyb…           1        39995 0.0-1.0          3999… &quot;&lt;p&gt;&lt;sp… 32       
##  3 fullscreen           2        44140 0.0-2.0          &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;     
##  4 html-keyb…           3        48023 0.0-3.0          3882… &quot;&lt;p sty… 32       
##  5 html-butt…           4        49837 0.0-4.0-0.0      812.…  &lt;NA&gt;    &lt;NA&gt;     
##  6 html-keyb…           5        50340 0.0-4.0-1.0      null  &quot;&lt;p sty… null     
##  7 html-keyb…           6        51345 0.0-4.0-2.0      null  &quot;&lt;p sty… null     
##  8 html-keyb…           7        52069 0.0-4.0-3.0      null  &quot;&lt;p sty… null     
##  9 html-butt…           8        52833 0.0-4.0-0.1      762.…  &lt;NA&gt;    &lt;NA&gt;     
## 10 html-keyb…           9        53335 0.0-4.0-1.1      null  &quot;&lt;p sty… null     
## # … with 315 more rows, and 6 more variables: success &lt;lgl&gt;,
## #   button_pressed &lt;dbl&gt;, left_right_s1 &lt;dbl&gt;, left_right_s2 &lt;dbl&gt;,
## #   reward_s1 &lt;dbl&gt;, reward_s2 &lt;dbl&gt;</code></pre>
<p>教示とか刺激が出た時(trial_typeがhtml-keyboard-response)やpavloviaの関数(trial_typeがpavlovia)は邪魔なので除外する（このデータはpavloviaで収集されました）。</p>
<pre class="r"><code>sub01 %&gt;% 
    filter(trial_type == &quot;html-button-response&quot;)</code></pre>
<pre><code>## # A tibble: 80 × 13
##    trial_type trial_index time_elapsed internal_node_id rt    stimulus key_press
##    &lt;chr&gt;            &lt;dbl&gt;        &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;    
##  1 html-butt…           4        49837 0.0-4.0-0.0      812.… &lt;NA&gt;     &lt;NA&gt;     
##  2 html-butt…           8        52833 0.0-4.0-0.1      762.… &lt;NA&gt;     &lt;NA&gt;     
##  3 html-butt…          12        55853 0.0-4.0-0.2      489.… &lt;NA&gt;     &lt;NA&gt;     
##  4 html-butt…          16        59331 0.0-4.0-0.3      1375… &lt;NA&gt;     &lt;NA&gt;     
##  5 html-butt…          20        63031 0.0-4.0-0.4      1011… &lt;NA&gt;     &lt;NA&gt;     
##  6 html-butt…          24        66559 0.0-4.0-0.5      928.… &lt;NA&gt;     &lt;NA&gt;     
##  7 html-butt…          28        70521 0.0-4.0-0.6      1152… &lt;NA&gt;     &lt;NA&gt;     
##  8 html-butt…          32        73915 0.0-4.0-0.7      756.… &lt;NA&gt;     &lt;NA&gt;     
##  9 html-butt…          36        77303 0.0-4.0-0.8      1195… &lt;NA&gt;     &lt;NA&gt;     
## 10 html-butt…          40        80805 0.0-4.0-0.9      1268… &lt;NA&gt;     &lt;NA&gt;     
## # … with 70 more rows, and 6 more variables: success &lt;lgl&gt;,
## #   button_pressed &lt;dbl&gt;, left_right_s1 &lt;dbl&gt;, left_right_s2 &lt;dbl&gt;,
## #   reward_s1 &lt;dbl&gt;, reward_s2 &lt;dbl&gt;</code></pre>
<p>まず，tiral番号を追加する。次に，s1の報酬確率を追加する(前半40試行は0.8,後半40試行は0.2)。選択に応じたフィードバックを追加する。必要な列だけ選択する。button_pressedはchoiceって名前にする。</p>
<pre class="r"><code>sub01 %&gt;% 
    filter(trial_type == &quot;html-button-response&quot;) %&gt;% 
  mutate(trial = 1:80, 
         s1_prob = rep(c(0.8,0.2),each = 40),
         reward = ifelse(button_pressed == 0, reward_s1, reward_s2)) %&gt;% 
  select(trial,choice=button_pressed, rt, reward, s1_prob,reward_s1, reward_s2)</code></pre>
<pre><code>## # A tibble: 80 × 7
##    trial choice rt                 reward s1_prob reward_s1 reward_s2
##    &lt;int&gt;  &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
##  1     1      0 812.3649999979534       1     0.8         1         0
##  2     2      0 762.6200000013341       1     0.8         1         1
##  3     3      0 489.58000000129687      1     0.8         1         1
##  4     4      0 1375.0050000016927      1     0.8         1         0
##  5     5      0 1011.4749999993364      1     0.8         1         0
##  6     6      0 928.5450000024866       1     0.8         1         0
##  7     7      0 1152.509999999893       1     0.8         1         0
##  8     8      0 756.2650000036228       1     0.8         1         0
##  9     9      0 1195.609999995213       0     0.8         0         0
## 10    10      0 1268.1650000013178      0     0.8         0         0
## # … with 70 more rows</code></pre>
<p>いい感じなので，これでsub01として上書きする。</p>
<pre class="r"><code>sub01 &lt;- sub01 %&gt;% 
    filter(trial_type == &quot;html-button-response&quot;) %&gt;% 
  mutate(trial = 1:80, 
         s1_prob = rep(c(0.2,0.8),each = 40),
         reward = ifelse(button_pressed == 0, reward_s1, reward_s2)) %&gt;% 
  select(trial,choice=button_pressed, rt, reward, s1_prob,reward_s1, reward_s2)
sub01</code></pre>
<pre><code>## # A tibble: 80 × 7
##    trial choice rt                 reward s1_prob reward_s1 reward_s2
##    &lt;int&gt;  &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
##  1     1      0 812.3649999979534       1     0.2         1         0
##  2     2      0 762.6200000013341       1     0.2         1         1
##  3     3      0 489.58000000129687      1     0.2         1         1
##  4     4      0 1375.0050000016927      1     0.2         1         0
##  5     5      0 1011.4749999993364      1     0.2         1         0
##  6     6      0 928.5450000024866       1     0.2         1         0
##  7     7      0 1152.509999999893       1     0.2         1         0
##  8     8      0 756.2650000036228       1     0.2         1         0
##  9     9      0 1195.609999995213       0     0.2         0         0
## 10    10      0 1268.1650000013178      0     0.2         0         0
## # … with 70 more rows</code></pre>
</div>
<div id="sub01の選択の可視化" class="section level4">
<h4>sub01の選択の可視化</h4>
<pre class="r"><code>sub01 %&gt;% 
  ggplot(aes(x = trial, y = s1_prob)) +
  geom_line() +
  geom_line(aes(x= trial, y = choice), colour = &#39;blue&#39;) +
  geom_point(aes(x = trial, y = reward),colour = &#39;red&#39;)</code></pre>
<p><img src="how-to-cognitive-modeling-rl1_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
</div>
<div id="名分のデータを読み込んでlong形式のデータにする"
class="section level4">
<h4>5名分のデータを読み込んでlong形式のデータにする</h4>
<p>１名ずつ読み込むのは大変なので，一気に処理をしてしまいましょう。for文でfile_namesに入っているデータの数の回数分処理をします。</p>
<pre class="r"><code># 確認用の図を入れる場所を確保
plot_check &lt;- NULL
# データを入れる場所を確保
data_long &lt;- NULL
for (i in 1:length(file_names)) {
  # file_namesのi番目のデータを読み込んで,上記の処理をして，tmp_dataに格納
  tmp_data &lt;- read_csv(paste(&quot;data&quot;,file_names[i], sep = &quot;/&quot;)) %&gt;% 
    filter(trial_type == &quot;html-button-response&quot;) %&gt;% 
    mutate(id = rep(i,80),
           trial = 1:80, 
           s1_prob = rep(c(0.2,0.8),each = 40),
           reward = ifelse(button_pressed == 0, reward_s1, reward_s2)) %&gt;% 
    select(id, trial,choice=button_pressed, rt, reward, s1_prob,reward_s1, reward_s2)
  # データの保存
  data_long &lt;- rbind(data_long, tmp_data)
  
  # plot
  plot_check[[i]] &lt;- ggplot(tmp_data, aes(x = trial, y = s1_prob)) +
    geom_line() +
    geom_line(aes(x= trial, y = choice), colour = &#39;blue&#39;) +
    geom_point(aes(x = trial, y = reward),colour = &#39;red&#39;)
}</code></pre>
</div>
</div>
</div>
<div id="d-パラメータ推定" class="section level2">
<h2>D パラメータ推定</h2>
<div id="解析の関数化" class="section level3">
<h3>解析の関数化</h3>
<p>以降は，繰り返しも多いので，dataフォルダ内のデータに対して，グリッドサーチを用いた最尤推定を行って結果を返す関数を準備します。idに番号をいれたら，そのid番号の参加者のパラメータを推定する関数として，estimate_gridを作りました。長いですが，上でやっていることを並べただけです。</p>
<pre class="r"><code>estimate_grid &lt;- function(data, id_no){
  #指定したidでグリッドサーチで推定
  tmp_data &lt;- data %&gt;% 
    filter(id == id_no)
  
  tmp_result &lt;- tmp_data %&gt;% 
    grid_search()
  #最尤推定を出力
  maxIndex &lt;- which.max(tmp_result$calc_results$store_loglike)
  print(paste(&quot;最尤推定値: α =&quot;,tmp_result$calc_results$store_alpha[maxIndex],
      &quot;β =&quot;,tmp_result$calc_results$store_beta[maxIndex], 
      &quot;,対数尤度: Log Likelihood = &quot;,tmp_result$calc_results$store_loglike[maxIndex]))
  #3dプロットを出力
  rownames(tmp_result$store_3d) &lt;- NULL
  y &lt;- seq(0,1,0.01)
  x &lt;- seq(0,15,0.2)
  image.plot(x,y,tmp_result$store_3d)
  
  #対数尤度を尤度へ
  matrix_ll &lt;- exp(tmp_result$store_3d)
  # 行（beta）ごとに平均をして、全体の平均で標準化
  beta_sum_ll &lt;- rowSums(matrix_ll)
  beta_marginal_like &lt;- beta_sum_ll/sum(beta_sum_ll)
  beta_marginal_like_data &lt;- data.frame(x,beta_marginal_like)
  colnames(beta_marginal_like_data) &lt;- c(&quot;parameter&quot;,&quot;marginal_like&quot;)
  # 列（alpha）ごとに平均をして、全体の平均で標準化
  alpha_sum_ll &lt;- colSums(matrix_ll)
  alpha_marginal_like &lt;- alpha_sum_ll/sum(alpha_sum_ll)
  alpha_marginal_like_data &lt;- data.frame(y,alpha_marginal_like)
  colnames(alpha_marginal_like_data) &lt;- c(&quot;parameter&quot;,&quot;marginal_like&quot;)
  #プロット
  p1 &lt;- beta_marginal_like_data %&gt;% 
    ggplot(aes( x = parameter, y = marginal_like)) +
    geom_line() +
    labs(x=&quot;Parameter β&quot;, y=&quot;p(data|model)&quot;)
  print(p1)
  
  p2 &lt;- alpha_marginal_like_data %&gt;% 
    ggplot(aes( x = parameter, y = marginal_like)) +
    geom_line() +
    labs(x=&quot;Parameter α&quot;, y=&quot;p(data|model)&quot;)
  print(p2)
  
  #q値など計算
  tmp_q &lt;- q_learning_ll(tmp_result$calc_results$store_alpha[maxIndex],
                         tmp_result$calc_results$store_beta[maxIndex],
                         tmp_data)
  #データにQ値などを追加
  tmp_data$value_s1 &lt;- tmp_q$result$value_s1
  tmp_data$value_s2 &lt;- tmp_q$result$value_s2
  tmp_data$prob_s1 &lt;- tmp_q$result$prob_s1
  
  p3&lt;- tmp_data %&gt;% 
    ggplot(aes(x = trial, y = s1_prob)) +
    geom_line() +
    geom_line(aes(x= trial, y = choice), colour = &#39;blue&#39;) +
    geom_line(aes(x= trial, y = prob_s1), colour = &#39;blue&#39;,linetype=&quot;dashed&quot;) +
    geom_point(aes(x = trial, y = reward),colour = &#39;red&#39;) +
    geom_line(aes(x= trial, y = value_s1), colour = &#39;green&#39;,linetype=&quot;dashed&quot;) +
    geom_line(aes(x= trial, y = value_s2), colour = &#39;orange&#39;,linetype=&quot;dashed&quot;) 
  print(p3)
}</code></pre>
</div>
<div id="モデルフィッティング" class="section level3">
<h3>モデル・フィッティング</h3>
<div id="sub01のモデルフィッティング" class="section level4">
<h4>sub01のモデル・フィッティング</h4>
<p>上の方で関数を定義したので，１行でいろいろと出力してくれます。なお，sub01は国里がかなりグリーディーな選択をしたので，βが15を越えてしまっています。</p>
<pre class="r"><code>estimate_grid(data = data_long, id_no = 1)</code></pre>
<pre><code>## [1] &quot;最尤推定値: α = 0.62 β = 15 ,対数尤度: Log Likelihood =  -2.44106911935233&quot;</code></pre>
<p><img src="how-to-cognitive-modeling-rl1_files/figure-html/unnamed-chunk-26-1.png" width="672" /><img src="how-to-cognitive-modeling-rl1_files/figure-html/unnamed-chunk-26-2.png" width="672" /><img src="how-to-cognitive-modeling-rl1_files/figure-html/unnamed-chunk-26-3.png" width="672" /><img src="how-to-cognitive-modeling-rl1_files/figure-html/unnamed-chunk-26-4.png" width="672" /></p>
</div>
<div id="sub02のモデルフィッティング" class="section level4">
<h4>sub02のモデル・フィッティング</h4>
<p>sub02は，国里が学習率が高くなるように反応をしてみました。</p>
<pre class="r"><code>estimate_grid(data = data_long, id = 2)</code></pre>
<pre><code>## [1] &quot;最尤推定値: α = 0.870000000000001 β = 1.6 ,対数尤度: Log Likelihood =  -44.7140662615762&quot;</code></pre>
<p><img src="how-to-cognitive-modeling-rl1_files/figure-html/unnamed-chunk-27-1.png" width="672" /><img src="how-to-cognitive-modeling-rl1_files/figure-html/unnamed-chunk-27-2.png" width="672" /><img src="how-to-cognitive-modeling-rl1_files/figure-html/unnamed-chunk-27-3.png" width="672" /><img src="how-to-cognitive-modeling-rl1_files/figure-html/unnamed-chunk-27-4.png" width="672" /></p>
</div>
<div id="演習-1" class="section level4">
<h4>演習</h4>
<p>sub03以降も確認して，自分のデータでも確かめてみよう！</p>
</div>
</div>
<div id="グリッドサーチの注意点" class="section level3">
<h3>グリッドサーチの注意点</h3>
<p>グリッドサーチの場合，探索範囲と探索の細かさは，研究者が決める。grid_search2()として，αは0から1の範囲だがキメが細かくない（0.2刻み）,βは肌目の細かさはかわらないが0から1の範囲で探索する関数を作ってみた。</p>
<pre class="r"><code>grid_search2 &lt;- function(data) {
  #　値を保存する変数の設定
  store_alpha &lt;- NULL　#サーチしたαの保存
  store_beta &lt;- NULL　 #サーチしたβの保存
  store_loglike &lt;- NULL　#計算した対数尤度の保存
  store_3d &lt;- NULL　#３次元プロット用
  store_ll &lt;- NULL　#store3Dの途中計算用に別途対数尤度を用意する
  # グリッドサーチの実施
  beta &lt;- 0
  for(m in 1:6){
    alpha &lt;- 0
    for(n in 1:6){
        result &lt;- q_learning_ll(alpha, beta,data)
        store_alpha[(m-1)*6+n] &lt;- alpha
        store_beta[(m-1)*6+n] &lt;- beta
        store_loglike[(m-1)*6+n] &lt;- result$ll
        store_ll[n] &lt;- result$ll
        # alpheを0.01刻みで増やす
        alpha &lt;- alpha + 0.2
    }  
    store_3d &lt;- rbind(store_3d,store_ll)
    #betaを0.2刻みで増やす
    beta　&lt;- beta + 0.2
  }
    calc_results&lt;- data_frame(store_alpha, store_beta, store_loglike)
    return(list(calc_results = calc_results, store_3d = store_3d))
}</code></pre>
<p>先程と同じgrid_searchと上記のgrid_search2で推定をしてみます。</p>
<pre class="r"><code>data &lt;- q_learning_sim(alpha = 0.3, beta = 6,data = sim_data) 
grid_result1 &lt;- grid_search(data)
grid_result2 &lt;- grid_search2(data)</code></pre>
<pre><code>## Warning: `data_frame()` was deprecated in tibble 1.1.0.
## Please use `tibble()` instead.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated.</code></pre>
<p>元々のグリッドサーチはいい感じに推定できていると思います。</p>
<pre class="r"><code>rownames(grid_result1$store_3d) &lt;- NULL
y &lt;- seq(0,1,0.01)
x &lt;- seq(0,15,0.2)
image.plot(x,y,grid_result1$store_3d)</code></pre>
<p><img src="how-to-cognitive-modeling-rl1_files/figure-html/unnamed-chunk-30-1.png" width="672" /></p>
<pre class="r"><code>maxIndex &lt;- which.max(grid_result1$calc_results$store_loglike)
paste(&quot;最尤推定値: α =&quot;,grid_result1$calc_results$store_alpha[maxIndex],
      &quot;β =&quot;,grid_result1$calc_results$store_beta[maxIndex], 
      &quot;,対数尤度: Log Likelihood = &quot;,grid_result1$calc_results$store_loglike[maxIndex])</code></pre>
<pre><code>## [1] &quot;最尤推定値: α = 0.21 β = 6.8 ,対数尤度: Log Likelihood =  -10.7381687527344&quot;</code></pre>
<p>当たり前ですが，間隔を広げたり，範囲を狭めると，範囲外の推定値は求まりませんし（βは範囲外），きめが荒いので，推定値もずれます。実際は，グリッドサーチではなく，最適化手法を使って最尤推定値を求めたり，ベイズ推定で求めたりします。ただ，推定においては，狭い範囲内で最も良いだけの値（局所最適解という）をもってくる可能性があるのは気をつけないといけません。</p>
<pre class="r"><code>maxIndex &lt;- which.max(grid_result2$calc_results$store_loglike)
paste(&quot;最尤推定値: α =&quot;,grid_result2$calc_results$store_alpha[maxIndex],
      &quot;β =&quot;,grid_result2$calc_results$store_beta[maxIndex], 
      &quot;,対数尤度: Log Likelihood = &quot;,grid_result2$calc_results$store_loglike[maxIndex])</code></pre>
<pre><code>## [1] &quot;最尤推定値: α = 0.6 β = 1 ,対数尤度: Log Likelihood =  -33.7595314670729&quot;</code></pre>
<pre class="r"><code>rownames(grid_result2$store_3d) &lt;- NULL
y &lt;- seq(0,1,0.2)
x &lt;- seq(0,1,0.2)
image.plot(x,y,grid_result2$store_3d)</code></pre>
<p><img src="how-to-cognitive-modeling-rl1_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
</div>
<div id="汎用最適化関数で最尤推定する" class="section level3">
<h3>汎用最適化関数で最尤推定する</h3>
<p>グリッドサーチはわかりやすいですが，上記のような問題もあるので，実際のパラメータ推定では，汎用最適化関数を用います。以下では，Rでよく使用されるoptim関数とより洗練されたアルゴリズムである粒子群最適化(Particle
Swarm
Optimization)を実装したpsoパッケージを用いたパラメータ推定について紹介します。</p>
<p>汎用最適化関数を使うために，q_learning_ll関数を少し変更して，パラメータとデータを与えたら，負の対数尤度を返すq_learning_nll関数を作ります（不要な部分を削除して，最後に対数尤度にマイナスをつけただけです）。</p>
<pre class="r"><code>q_learning_nll &lt;- function(par,data) {
  alpha &lt;- par[1]
  beta &lt;- par[2]
  #変数の準備
  value_s1 &lt;- 0          # s1の価値(初期値は0)
  value_s2 &lt;- 0          # s2の価値(初期値は0)
  prob_s1 &lt;- NULL  # s1の選択確率
  ll &lt;- 0                 # 対数尤度
  # Qlearningモデル
  for (i in 1:nrow(data)){
    # s1を選ぶ確率を計算
    prob_s1[i] &lt;- exp(beta*value_s1[i])/(exp(beta*value_s1[i])+exp(beta*value_s2[i]))
    #FBを報酬(r)として、価値の更新を行う。
    if (data$choice[i] == 1){
        #予測誤差の計算
        prediction_error &lt;-  data$reward[i] - value_s1[i]
        #予測誤差を使ってs1の価値を更新する
        value_s1[i+1] &lt;- value_s1[i]+alpha*prediction_error
        #s2は更新なし
        value_s2[i+1] &lt;- value_s2[i]
        # 対数尤度の計算のために選択したs1を選ぶ確率の対数を加算
        ll &lt;- ll + log(prob_s1[i])
    }else{
        #予測誤差の計算
        prediction_error &lt;- data$reward[i] - value_s2[i]
        #予測誤差を使ってs2の価値を更新する
        value_s2[i+1] &lt;- value_s2[i]+alpha*prediction_error
        #s1は更新なし
        value_s1[i+1] &lt;- value_s1[i]
        # 対数尤度の計算のために選択したs2を選ぶ確率の対数を加算
        ll &lt;- ll + log(1-prob_s1[i])
    }
  }
  return(-ll)
}</code></pre>
<p>今回は，sub03のデータでグリッドサーチ，optim,
psoの推定をしてみましょう。まずは，データを用意して，グリッドサーチをしてみます。</p>
<pre class="r"><code># データの用意
sub03_data &lt;- data_long %&gt;% 
    filter(id == 3)

# グリッドサーチ
result_grid &lt;- grid_search(sub03_data)
maxIndex &lt;- which.max(result_grid$calc_results$store_loglike)
alpha_grid &lt;- result_grid$calc_results$store_alpha[maxIndex]
beta_grid &lt;- result_grid$calc_results$store_beta[maxIndex]
loglike_grid &lt;- result_grid$calc_results$store_loglike[maxIndex]
print(paste(&quot;最尤推定値: α =&quot;,result_grid$calc_results$store_alpha[maxIndex],
      &quot;β =&quot;,result_grid$calc_results$store_beta[maxIndex], 
      &quot;,対数尤度: Log Likelihood = &quot;,result_grid$calc_results$store_loglike[maxIndex]))</code></pre>
<pre><code>## [1] &quot;最尤推定値: α = 0.7 β = 2.2 ,対数尤度: Log Likelihood =  -38.8582274622813&quot;</code></pre>
<div id="optim" class="section level4">
<h4>optim</h4>
<p>optimは与えられた関数の出力値を最小化するパラメータを探索する関数です。parにパラメータの初期値（これを変えると結果も変わるので工夫が必要ですが，今回は適当に0.5にしています），fnに負の対数尤度を返す関数，dataにデータ，methodに使用するアルゴリズム（今回は，L-BFGS-Bです），lowerにパラメータの下限（fnで定義しているように，１つ目がα，１つ目がβです），upoerにパラメータの上限（fnで定義しているように，１つ目がα，１つ目がβです）を指定して実行します。</p>
<pre class="r"><code>result_optim &lt;- optim(par = c(0.5,0.5),
      fn = q_learning_nll,
      data = sub03_data,
      method = &quot;L-BFGS-B&quot;,
      lower = c(0,0),
      upper = c(1,15))


print(paste(&quot;最尤推定値: α =&quot;,result_optim$par[1],&quot;β =&quot;,result_optim$par[2], &quot;,対数尤度: Log Likelihood = &quot;, -result_optim$value))</code></pre>
<pre><code>## [1] &quot;最尤推定値: α = 0.69121145496389 β = 2.26477480079629 ,対数尤度: Log Likelihood =  -38.8506377123627&quot;</code></pre>
</div>
<div id="pso" class="section level4">
<h4>pso</h4>
<p>粒子群最適化(pso)は，最小値の探索において，複数の初期値からスタートして，局所的な最小化と全体としての最小化を同時に行うことで局所最適解に陥らないように工夫された最適化アルゴリズムです。粒子群最適化について説明は，<a
href="result_pso">こちら</a>が簡潔でわかりやすいかと思います。psoパッケージは，optimと同じ使い方ができるように，引数の設定と出力が同じになっています。optimと同様に以下のように設定して，実行します。</p>
<pre class="r"><code>result_pso &lt;- psoptim(par = c(0.5,0.5),
                      fn = q_learning_nll,
                      data = sub03_data,
                      lower = c(0,0),
                      upper = c(1,15))

print(paste(&quot;最尤推定値: α =&quot;,result_pso$par[1],&quot;β =&quot;,result_pso$par[2], &quot;,対数尤度: Log Likelihood = &quot;, -result_pso$value))</code></pre>
<pre><code>## [1] &quot;最尤推定値: α = 0.691211119372265 β = 2.26477599855068 ,対数尤度: Log Likelihood =  -38.8506377123594&quot;</code></pre>
</div>
<div id="つの比較" class="section level4">
<h4>３つの比較</h4>
<p>ほとんど同じ結果になりますが，一応並べてみます。手法選択は，パラメータリカバリの結果を元にして，推定精度とコスト（主に時間的なコスト）を考慮して，選択することになります。</p>
<pre class="r"><code>method &lt;- c(&quot;grid&quot;, &quot;optim&quot;, &quot;pso&quot;)
alpha &lt;- c(result_grid$calc_results$store_alpha[maxIndex],result_optim$par[1],result_pso$par[1])
beta &lt;- c(result_grid$calc_results$store_beta[maxIndex],result_optim$par[2],result_pso$par[2])
loglikelihood &lt;- c(result_grid$calc_results$store_loglike[maxIndex],-result_optim$value,-result_pso$value)

compare_table &lt;- tibble(method,alpha,beta, loglikelihood)

knitr::kable(compare_table)</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">method</th>
<th align="right">alpha</th>
<th align="right">beta</th>
<th align="right">loglikelihood</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">grid</td>
<td align="right">0.7000000</td>
<td align="right">2.200000</td>
<td align="right">-38.85823</td>
</tr>
<tr class="even">
<td align="left">optim</td>
<td align="right">0.6912115</td>
<td align="right">2.264775</td>
<td align="right">-38.85064</td>
</tr>
<tr class="odd">
<td align="left">pso</td>
<td align="right">0.6912111</td>
<td align="right">2.264776</td>
<td align="right">-38.85064</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div id="引用参考文献" class="section level2">
<h2>引用・参考文献</h2>
<ul>
<li>Busemeyer, J. R., &amp; Diederich, A. (2010). Cognitive Modeling.
SAGE.</li>
<li>Heathcote, A., Brown, S. D., &amp; Wagenmakers, E.-J. (2015). An
Introduction to Good Practices in Cognitive Modeling. In B. U. Forstmann
&amp; E.-J. Wagenmakers (Eds.), An Introduction to Model-Based Cognitive
Neuroscience (pp. 25–48). Springer New York.</li>
<li>Palminteri, S., Wyart, V., &amp; Koechlin, E. (2017). The Importance
of Falsification in Computational Cognitive Modeling. Trends in
Cognitive Sciences, 21(6), 425–433.</li>
</ul>
</div>

<footer>
  <p>Copyright &copy; 2013-2022 Yoshihiko Kunisato. All rights reserved </p>
</footer>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
