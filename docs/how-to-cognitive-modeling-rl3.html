<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>強化学習モデル: ベイズ推定(2)</title>

<script src="site_libs/header-attrs-2.7/header-attrs.js"></script>
<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link rel="apple-touch-icon" type="image/png" href="apple-touch-icon-180x180.png">
<link rel="icon" type="image/png" href="icon-192x192.png">


<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>





<link rel="stylesheet" href="site_style.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-sm-12 col-md-4 col-lg-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-sm-12 col-md-8 col-lg-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Computational Clinical Psychology Lab</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="research.html">Research</a>
</li>
<li>
  <a href="team.html">Team</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Publications
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="book.html">書籍</a>
    </li>
    <li>
      <a href="articles.html">学術論文</a>
    </li>
    <li>
      <a href="articles-japanese.html">学術論文（日本語）</a>
    </li>
    <li>
      <a href="bulletin.html">紀要論文</a>
    </li>
    <li>
      <a href="presentation.html">国際会議発表</a>
    </li>
    <li>
      <a href="presentation-japanese.html">国内学会・研究会発表</a>
    </li>
  </ul>
</li>
<li>
  <a href="code_tips.html">Code &amp; Tips</a>
</li>
<li>
  <a href="education.html">Education</a>
</li>
<li>
  <a href="news.html">News</a>
</li>
<li>
  <a href="https://kunisatolab.github.io/english/index.html">English</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">強化学習モデル: ベイズ推定(2)</h1>

</div>


<div id="認知モデリングの推奨実践法" class="section level2">
<h2>認知モデリングの推奨実践法</h2>
<p>Busemeyer &amp; Diederich(2010), Heathcote (2014), Palminteri et al.(2017)を参考にまとめると，以下のような感じになります。</p>
<ul>
<li>A 認知課題と認知モデルを準備</li>
<li>B 人工データ生成とパラメータリカバリーを確認（モデルや課題の修正）</li>
<li>C データ収集と行動データを確認</li>
<li>D パラメータ推定</li>
<li>E 相対モデル比較</li>
<li>F モデル・シミュレーションと選択的影響テスト</li>
</ul>
<p><a href="https://kunisatolab.github.io/main/how-to-cognitive-modeling-rl1.html" target="_blank">「強化学習モデル: 最尤推定」</a>と<a href="https://kunisatolab.github.io/main/how-to-cognitive-modeling-rl2.html" target="_blank">「強化学習モデル: ベイズ推定(1)」</a>では，ABCDとすすめてきました。今回は，今回は，EとFについて説明します（相対モデル比較に関連づけてモデル・リカバリーの説明もします）。</p>
<div id="使用するrパッケージ" class="section level3">
<h3>使用するRパッケージ</h3>
<p>適宜必要なパッケージをインストールしてください(<a href="https://kunisatolab.github.io/main/how-to-cognitive-modeling-rl2.html" target="_blank">「強化学習モデル: ベイズ推定(1)」</a>と同じです)。</p>
<pre class="r"><code>rm(list = ls())
library(tidyverse)
library(cmdstanr)
library(rstan)
library(posterior)
library(bridgesampling)</code></pre>
<p><a href="https://kunisatolab.github.io/main/how-to-cognitive-modeling-rl2.html" target="_blank">「強化学習モデル: ベイズ推定(1)」</a>と同じく，人工データを生成するために，実験状況の入ったsim_dataの準備とq_learning_sim関数を準備をします。</p>
<pre class="r"><code>sim_data &lt;- tibble(trial = 1:80,
                   prob_s1 = rep(c(0.2, 0.8), each = 40),
                   prob_s2 = rep(c(0.8, 0.2), each = 40),
                   reward_s1 = ifelse(runif(80) &lt; prob_s1, 1, 0),
                   reward_s2 = ifelse(runif(80) &lt; prob_s2, 1, 0))

q_learning_sim &lt;- function(alpha, beta,data) {
  #変数の準備
  value_s1 &lt;- 0          # s1の価値(初期値は0)
  value_s2 &lt;- 0          # s2の価値(初期値は0)
  current_choice &lt;- NULL     # ある時点の選択（1=s1，0=s2）
  choice_prob_s1 &lt;- NULL  # s1の選択確率
  reward &lt;- NULL                 # 報酬
  # Qlearningモデル
  for (i in 1:nrow(data)){
    # s1を選ぶ確率を計算し,一様分布から発生させた乱数が行動選択確率よりも小さい時に1（s1），大きい時に0（s2）
    choice_prob_s1[i] &lt;- exp(beta*value_s1[i])/(exp(beta*value_s1[i])+exp(beta*value_s2[i]))
    current_choice[i] &lt;- as.integer(runif(1,min=0,max=1) &lt;= choice_prob_s1[i])
    #FBを報酬(r)として、価値の更新を行う。
    if (current_choice[i] == 1){
        reward[i] &lt;- data$reward_s1[i]
        #予測誤差の計算
        prediction_error &lt;-  reward[i] - value_s1[i]
        #予測誤差を使ってs1の価値を更新する
        value_s1[i+1] &lt;- value_s1[i]+alpha*prediction_error
        #s2は更新なし
        value_s2[i+1] &lt;- value_s2[i]
    }else{
        reward[i] &lt;- data$reward_s2[i]
        #予測誤差の計算
        prediction_error &lt;- reward[i] - value_s2[i]
        #予測誤差を使ってs2の価値を更新する
        value_s2[i+1] &lt;- value_s2[i]+alpha*prediction_error
        #s1は更新なし
        value_s1[i+1] &lt;- value_s1[i]
    }
  }
  result &lt;- data.frame(trial = data$trial,
              value_s1 = value_s1[1:nrow(data)], 
              value_s2 = value_s2[1:nrow(data)], 
              prob_s1 = choice_prob_s1,
              choice = current_choice,
              reward = reward)
  return(result)
}

# データの準備
setwd(&quot;data&quot;)
file_names &lt;- list.files()
setwd(&quot;..&quot;)
# 確認用の図を入れる場所を確保
plot_check &lt;- NULL
# データを入れる場所を確保
data_long &lt;- NULL
for (i in 1:length(file_names)) {
  # file_namesのi番目のデータを読み込んで,上記の処理をして，tmp_dataに格納
  tmp_data &lt;- read_csv(paste(&quot;data&quot;,file_names[i], sep = &quot;/&quot;)) %&gt;% 
    filter(trial_type == &quot;html-button-response&quot;) %&gt;% 
    mutate(id = rep(i,80),
           trial = 1:80, 
           s1_prob = rep(c(0.2,0.8),each = 40),
           reward = ifelse(button_pressed == 0, reward_s1, reward_s2)) %&gt;% 
    select(id, trial,choice=button_pressed, rt, reward, s1_prob,reward_s1, reward_s2)
  # データの保存
  data_long &lt;- rbind(data_long, tmp_data)
}</code></pre>
</div>
</div>
<div id="e-相対モデル比較" class="section level2">
<h2>E 相対モデル比較</h2>
<p><a href="https://kunisatolab.github.io/main/how-to-cognitive-modeling-rl2.html" target="_blank">「強化学習モデル: ベイズ推定(1)」</a>の最後に検討したように，sub01のデータの推定結果からは，有情報事前分布の方が良さそうに思えますが，ここはモデル比較をしてみたいと思います。モデル比較する場合には，以下の２種類があります。今回は，予測をしたいという話ではないので，WBICを使用します。</p>
<ul>
<li><p>予測の良さに基づくモデル選択法：KL距離をベースにしたものであり，予測をする上で悪いものを避けるという保守的なモデル選択ができる。例えば，AIC, DIC，WAICなどがあります。</p></li>
<li><p>ベイズ的なモデル選択法(モデルと事前分布からみてどのくらいデータが意外か。この意外性が小さいほど良いモデルと考えられる)：BIC, WBIC, ベイズファクター,自由エネルギー</p></li>
</ul>
<p>WBICの計算をする場合は，stanコードの対数尤度の計算の部分で対数尤度に(1/log(データ数)) を掛ける必要があります。さらに，generated quantitiesブロックで対数尤度を計算します。それぞれは，以下になります。</p>
<ul>
<li>q_learning_WBIC.stan</li>
</ul>
<pre><code>data {
  int&lt;lower=1&gt; trial;
  int&lt;lower=1,upper=2&gt; choice[trial]; // 1 or 2
  int&lt;lower=0,upper=1&gt; reward[trial]; // 0 or 1
}
parameters {
  real&lt;lower=0.0,upper=1.0&gt; alpha; //学習率
  real&lt;lower=0.0&gt; beta;            //逆温度
}
model {
  //学習率と逆温度の事前分布の指定はしていないので，parametersで指定した範囲の無情報事前分布が使われる
  matrix[trial,2] Q;
  Q[1, 1] = 0;
  Q[1, 2] = 0;
  
  for ( t in 1:trial) {
    // 対数尤度を足す
    target += (1/log(trial))*log(exp(beta*Q[t,choice[t]])/(exp(beta*Q[t,choice[t]])+exp(beta*Q[t,3-choice[t]])));
    
    if (t &lt; trial) {
      // 選択された選択肢のQ値の更新
      Q[t+1,choice[t]] = Q[t, choice[t]] + alpha * (reward[t] - Q[t, choice[t]]);
      // 選択されなかった選択肢は更新しない
      Q[t+1, 3- choice[t]] = Q[t, 3- choice[t]];
    }
  }
}
generated quantities {
  vector[trial] log_lik;
  {
    matrix[trial, 2] Q;
    Q[1, 1] = 0;
    Q[1, 2] = 0;
    for ( t in 1:trial ) {
       log_lik[t] =  log(exp(beta*Q[t,choice[t]])/(exp(beta*Q[t,choice[t]])+exp(beta*Q[t,3-choice[t]])));
      if (t &lt; trial) {
        // 選択された選択肢のQ値の更新
        Q[t+1,choice[t]] = Q[t, choice[t]] + alpha * (reward[t] - Q[t, choice[t]]);
        // 選択されなかった選択肢は更新しない
        Q[t+1, 3- choice[t]] = Q[t, 3- choice[t]];
      }
    }
  }
}</code></pre>
<ul>
<li>q_learning_prior_WBIC.stan</li>
</ul>
<pre><code>data {
  int&lt;lower=1&gt; trial;
  int&lt;lower=1,upper=2&gt; choice[trial]; // 1 or 2
  int&lt;lower=0,upper=1&gt; reward[trial]; // 0 or 1
}
parameters {
  real&lt;lower=0.0,upper=1.0&gt; alpha; //学習率
  real&lt;lower=0.0&gt; beta;            //逆温度
}
model {
  matrix[trial,2] Q;
  Q[1, 1] = 0;
  Q[1, 2] = 0;
  
  //学習率の事前分布にベータ分布，逆温度の事前分布にガンマ分布
  alpha ~ beta(2, 2); 
  beta ~ gamma(2, 0.5);
  
  for ( t in 1:trial) {
    // 対数尤度を足す
    target += (1/log(trial))*log(exp(beta*Q[t,choice[t]])/(exp(beta*Q[t,choice[t]])+exp(beta*Q[t,3-choice[t]])));
    
    if (t &lt; trial) {
      // 選択された選択肢のQ値の更新
      Q[t+1,choice[t]] = Q[t, choice[t]] + alpha * (reward[t] - Q[t, choice[t]]);
      // 選択されなかった選択肢は更新しない
      Q[t+1, 3- choice[t]] = Q[t, 3- choice[t]];
    }
  }
}
generated quantities {
  vector[trial] log_lik;
  {
    matrix[trial, 2] Q;
    Q[1, 1] = 0;
    Q[1, 2] = 0;
    for ( t in 1:trial ) {
       log_lik[t] =  log(exp(beta*Q[t,choice[t]])/(exp(beta*Q[t,choice[t]])+exp(beta*Q[t,3-choice[t]])));
      if (t &lt; trial) {
        // 選択された選択肢のQ値の更新
        Q[t+1,choice[t]] = Q[t, choice[t]] + alpha * (reward[t] - Q[t, choice[t]]);
        // 選択されなかった選択肢は更新しない
        Q[t+1, 3- choice[t]] = Q[t, 3- choice[t]];
      }
    }
  }
}</code></pre>
<div id="wbicによるモデル比較" class="section level3">
<h3>WBICによるモデル比較</h3>
<p>推定してモデル比較してみましょう。まずは，モデルをコンパイルします。</p>
<pre><code>q_learning_WBIC &lt;- cmdstan_model(&#39;q_learning_WBIC.stan&#39;)
q_learning_prior_WBIC &lt;- cmdstan_model(&#39;q_learning_prior_WBIC.stan&#39;)</code></pre>
<p>それでは，sub01で推定をしてみましょう！</p>
<pre><code>data_individual &lt;- data_long %&gt;% 
  filter(id == 1)

q_learning_WBIC_mcmc &lt;- q_learning_WBIC$sample(
        data = list(trial = nrow(data_individual),
                   reward = data_individual$reward,
                   choice = data_individual$choice + 1),
        seed = 123,
        chains = 4,
        iter_warmup = 500,
        iter_sampling = 2000,
        parallel_chains = 4)

q_learning_prior_WBIC_mcmc &lt;- q_learning_prior_WBIC$sample(
        data = list(trial = nrow(data_individual),
                   reward = data_individual$reward,
                   choice = data_individual$choice + 1),
        seed = 123,
        chains = 4,
        iter_warmup = 500,
        iter_sampling = 10000,
        parallel_chains = 4)

q_learning_WBIC_sample &lt;- rstan::read_stan_csv(q_learning_WBIC_mcmc$output_files())
q_learning_prior_WBIC_sample &lt;- rstan::read_stan_csv(q_learning_prior_WBIC_mcmc$output_files())</code></pre>
<p>予想に反して，無情報事前分布の方がWBICが低くなりました（低いほどよい）。一方，sub02では，有情報の方がWBICが小さくなりました。個人ごとには適切なモデルや事前分布は違う可能性があるので，階層モデルを作って評価が必要も思われます。</p>
<pre class="r"><code>WBIC_non &lt;- -mean(rowSums(rstan::extract(q_learning_WBIC_sample)$log_lik))
WBIC_prior &lt;- -mean(rowSums(rstan::extract(q_learning_prior_WBIC_sample)$log_lik))
paste(&quot;無情報事前分布のWBICは&quot;,WBIC_non)</code></pre>
<pre><code>## [1] &quot;無情報事前分布のWBICは 3.42081097633143&quot;</code></pre>
<pre class="r"><code>paste(&quot;有情報事前分布のWBICは&quot;,WBIC_prior)</code></pre>
<pre><code>## [1] &quot;有情報事前分布のWBICは 6.43904859965286&quot;</code></pre>
</div>
</div>
<div id="モデルリカバリーmodel-recovery" class="section level2">
<h2>モデルリカバリー（Model Recovery）</h2>
<p>これまでパラメータリカバリーをパラメータ推定のチェックに用いてきました。特定のモデルのパラメータ推定の精度を調べる上では，パラメータリカバリーが使えます。ただし，そもそもデータ生成に用いたれたモデルがモデル選択でちゃんと選ばれるのかについては，検討ができていません。生成モデルはあくまで研究者が仮定したものであって，複数の生成モデルが存在すると考えられるので，データからちゃんとモデルが選択できることが重要です。</p>
<p>パラメータ推定後の相対モデル比較において，データ生成過程で用いられた生成モデルがちゃんと選ばれるか確認するモデルリカバリーという考えがあります(Wilson &amp; Collins, 2019)。例えば，特定の生成モデルAから生成されたシミュレーションデータに対して，複数の生成モデルA ,B,Cを用いてパラメータ推定してモデル比較した場合，BやCよりもAが選ばれる必要があります。これを検討するのがモデルリカバリーです。モデルリカバリーでは，全ての生成モデルから異なる値のパラメータを用いてシミュレーションデータを生成し，それらに対して，全ての生成モデルを用いてパラメータ推定を行うことを全ての組み合わせで行います。モデルリカバリーによって，検討しているモデルが研究目的から妥当か，追加すべきモデルはないか，パラメータ推定で識別不可能なモデルはないかを検討することができます。</p>
<div id="モデルリカバリーで用いるモデル" class="section level3">
<h3>モデルリカバリーで用いるモデル</h3>
<p>あまり複雑にしないために，これまで用いてきたモデルとそのモデルを一部改変したモデルを考えます。</p>
<ul>
<li>上記で検討した事前分布をおいた強化学習モデル（Model 1）</li>
<li>上記からβを除外した強化学習モデル（Model 2, β=1に仮定したモデルともいえます）</li>
</ul>
<div id="αとβを仮定したモデルmodel-1から生成されたデータのモデルリカバリー" class="section level4">
<h4>αとβを仮定したモデル(Model 1)から生成されたデータのモデルリカバリー</h4>
<p>まずは，これまでと同様なαもβも存在する強化学習モデル(Model 1)でデータを生成します。それに対して，それと一致したモデル（Model 1, 上記のq_learning_prior_WBIC.stan）と一致しないモデル（Model 2, 以下のq_learning_prior_non_beta_WBIC.stan）を使って推定することで，モデルリカバリーをします。</p>
<p>q_learning_prior_non_beta_WBIC.stanは，以下のようなコードになります。簡単にいうと，q_learning_weak_info_single_WBIC.stanからbetaを抜いただけです。</p>
<pre><code>data {
  int&lt;lower=1&gt; trial;
  int&lt;lower=1,upper=2&gt; choice[trial]; // 1 or 2
  int&lt;lower=0,upper=1&gt; reward[trial]; // 0 or 1
}

parameters {
  real&lt;lower=0.0,upper=1.0&gt; alpha; //学習率
}

model {
  matrix[trial,2] Q;
  Q[1, 1] = 0;
  Q[1, 2] = 0;
  //学習率の事前分布にベータ分布
  alpha ~ beta(2, 2);
  for ( t in 1:trial) {
    // 対数尤度を足す
    target += (1/log(trial))*log(exp(Q[t,choice[t]])/(exp(Q[t,choice[t]])+exp(Q[t,3-choice[t]])));
    
    if (t &lt; trial) {
      // 選択された選択肢のQ値の更新
      Q[t+1,choice[t]] = Q[t, choice[t]] + alpha * (reward[t] - Q[t, choice[t]]);
      // 選択されなかった選択肢は更新しない
      Q[t+1, 3- choice[t]] = Q[t, 3- choice[t]];
    }
  }
}

generated quantities {
  vector[trial] log_lik;
  {
    matrix[trial, 2] Q;
    Q[1, 1] = 0;
    Q[1, 2] = 0;
    for ( t in 1:trial ) {
       log_lik[t] =  log(exp(Q[t,choice[t]])/(exp(Q[t,choice[t]])+exp(Q[t,3-choice[t]])));
      if (t &lt; trial) {
        // 選択された選択肢のQ値の更新
        Q[t+1,choice[t]] = Q[t, choice[t]] + alpha * (reward[t] - Q[t, choice[t]]);
        // 選択されなかった選択肢は更新しない
        Q[t+1, 3- choice[t]] = Q[t, 3- choice[t]];
      }
    }
  }
}</code></pre>
<p>まずは，q_learning_prior_non_beta_WBIC.stanをコンパイルします。</p>
<pre><code>q_learning_prior_non_beta_WBIC &lt;- cmdstan_model(&#39;q_learning_prior_non_beta_WBIC.stan&#39;)</code></pre>
<p>さて，以下のコードを走らせて，αとβを仮定したモデル(Model 1)で生成されたデータをαとβを仮定するモデル(Model 1)とαだけを仮定するモデル(Model 2)でフィッティングした時に，モデルが選択される確率を計算します。以下では，100回シミュテーションデータを生成して，MCMCで推定をするのでかなり時間がかかると思います（メモリもかなり使うと予想されます）。</p>
<pre><code>better_model1 &lt;- 0
n_simulation &lt;- 100
for (i in 1:n_simulation) {
  alpha_set &lt;- rbeta(1, 2, 2)
  beta_set &lt;- rgamma(1, 2, 0.5)
  #データ生成
  data_2 &lt;- q_learning_sim(alpha = alpha_set, beta = beta_set, sim_data)
  print(paste(&quot;進捗状況：&quot;,i,&quot;/&quot;,n_simulation))
  #パラメータ推定(推定がミスった時用にtryCatch関数を準備)
  tryCatch({
    with_beta_WBIC &lt;- q_learning_prior_WBIC$sample(
      data = list(trial = nrow(data_2),
                   reward = data_2$reward,
                   choice = data_2$choice + 1),
      seed = 123,
      chains = 4,
      iter_warmup = 500,
      iter_sampling = 3000,
      parallel_chains = 4)

    non_beta_WBIC &lt;- q_learning_prior_non_beta_WBIC$sample(
      data = list(trial = nrow(data_2),
                   reward = data_2$reward,
                   choice = data_2$choice + 1),
      seed = 123,
      chains = 4,
      iter_warmup = 500,
      iter_sampling = 3000,
      parallel_chains = 4)
      
    with_beta_WBIC_sample &lt;- rstan::read_stan_csv(with_beta_WBIC$output_files())
    WBIC_with_beta &lt;- -mean(rowSums(rstan::extract(with_beta_WBIC_sample)$log_lik))
    non_beta_WBIC_sample &lt;- rstan::read_stan_csv(non_beta_WBIC$output_files())
    WBIC_no_beta &lt;- -mean(rowSums(rstan::extract(non_beta_WBIC_sample)$log_lik))
    better_model1 &lt;- better_model1 + ifelse(WBIC_with_beta &lt; WBIC_no_beta, 1, 0)
  },error = function(e) {message(e)})
}

fit_model1_sim_model1 &lt;- better_model1/n_simulation
fit_model2_sim_model1 &lt;- (n_simulation - better_model1) / n_simulation</code></pre>
</div>
<div id="αのみを仮定したモデルmodel-2から生成されたデータのモデルリカバリー" class="section level4">
<h4>αのみを仮定したモデル(Model 2)から生成されたデータのモデルリカバリー</h4>
<p>次は，αのみを仮定したモデル（Model 2, βは仮定しない，つまり，βを１に固定するモデル）で生成されたデータをαとβを仮定するモデル(Model 1)とαだけを仮定するモデル(Model 2)でフィッティングした時に，モデルが選択される確率を計算します。以下では，100回シミュテーションデータを生成して，MCMCで推定をするのでかなり時間がかかると思います（メモリもかなり使うと予想されます）。</p>
<pre><code>better_model1 &lt;- 0
n_simulation &lt;- 100
beta_set &lt;- 1
for (i in 1:n_simulation) {
    alpha_set = alpha_set + 0.01
    #データ生成
    data_2 &lt;- q_learning_sim(alpha = alpha_set, beta = beta_set, sim_data)
    print(paste(&quot;進捗状況：&quot;,i,&quot;/&quot;,n_simulation))
    #パラメータ推定(推定がミスった時用にtryCatch関数を準備)
    tryCatch({
      with_beta_WBIC &lt;- q_learning_prior_WBIC$sample(
        data = list(trial = nrow(data_2),
                   reward = data_2$reward,
                   choice = data_2$choice + 1),
        seed = 123,
        chains = 4,
        iter_warmup = 500,
        iter_sampling = 3000,
        parallel_chains = 4)

      non_beta_WBIC &lt;- q_learning_prior_non_beta_WBIC$sample(
        data = list(trial = nrow(data_2),
                   reward = data_2$reward,
                   choice = data_2$choice + 1),
        seed = 123,
        chains = 4,
        iter_warmup = 500,
        iter_sampling = 3000,
        parallel_chains = 4)
      
    with_beta_WBIC_sample &lt;- rstan::read_stan_csv(with_beta_WBIC$output_files())
    WBIC_with_beta &lt;- -mean(rowSums(rstan::extract(with_beta_WBIC_sample)$log_lik))
    non_beta_WBIC_sample &lt;- rstan::read_stan_csv(non_beta_WBIC$output_files())
    WBIC_no_beta &lt;- -mean(rowSums(rstan::extract(non_beta_WBIC_sample)$log_lik))
    better_model1 &lt;- better_model1 + ifelse(WBIC_with_beta &lt; WBIC_no_beta, 1, 0)
  },error = function(e) {message(e)})
}

fit_model1_sim_model2 &lt;- better_model1 / n_simulation
fit_model2_sim_model2 &lt;- (n_simulation - better_model1) / n_simulation</code></pre>
<p>ヒートマップ形式で図示します。alphaだけのモデル(Model 2)で生成したデータのパタメータ推定において，高い確率でalphaだけのモデル(Model 2)が選択されています。一方，alphaとbetaの両方があるモデル(Model 1)で生成したデータのパラメータ推定においては，alphaとbetaの両方があるモデル(Model 1)の方が選択される確率は高いもののalphaだけのモデル(Model 2)が選択されることがあります。偶然，設定したパラメータがβが１付近になってモデル識別が難しくなるケースがあったり，alphaとbetaの両方があるモデル(Model 1)の方が推定するパラメータが多いというのもあるかもしれません。こんな感じでモデルリカバリーの検討を行います。</p>
<pre class="r"><code>simulated_model &lt;- factor(c(&quot;Model 1&quot;,&quot;Model 1&quot;,&quot;Model 2&quot;,&quot;Model 2&quot;), levels = c(&quot;Model 2&quot;,&quot;Model 1&quot;))
fit_model &lt;- factor(c(&quot;Model 1&quot;,&quot;Model 2&quot;,&quot;Model 1&quot;,&quot;Model 2&quot;), levels = c(&quot;Model 1&quot;,&quot;Model 2&quot;))
Probability &lt;- c(fit_model1_sim_model1, fit_model2_sim_model1, fit_model1_sim_model2, fit_model2_sim_model2)
model_recovery &lt;- tibble(simulated_model, fit_model, Probability)

ggplot(model_recovery, aes(x = fit_model, y = simulated_model, fill = Probability)) +
  geom_tile() +
  scale_fill_gradient(low = &quot;white&quot;, high = &quot;red&quot;) +
  geom_text(aes(label = round(Probability, digits = 2)), color = &quot;black&quot;)　+
  xlab(&quot;Fit Model&quot;) +
  ylab(&quot;Simulated Model&quot;)</code></pre>
<p><img src="how-to-cognitive-modeling-rl3_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
</div>
</div>
</div>
<div id="f-モデルシミュレーションと選択的影響テスト" class="section level2">
<h2>F モデル・シミュレーションと選択的影響テスト</h2>
<p>モデル・シミュレーションでは，<a href="https://kunisatolab.github.io/main/how-to-cognitive-modeling-rl1.html" target="_blank">「強化学習モデル: 最尤推定」</a>で行ったような人工データ生成を最もフィットの良かった推定値を用いて行います。複数のモデルの中で最もデータ適合が良いモデルであったとしても，それは相対的に良いモデルになります。私達が想定したモデルはどれも悪いモデルだった場合は，相対的には良いモデルを選ぶことはできても，それが絶対的には悪いモデルある可能性があります。そこで，情報量規準などで最も良いとされたモデルの推定値を用いて，人工データ生成を行って，その生成されたデータが現実のデータに近いものかを評価します。モデルシミュレーションについては，Palminteri, Wyart, &amp; Koechlin(2017)が詳しいです。</p>
<p>選択的影響テストとは，実験的操作を用いて，認知モデルの妥当性を検討する方法です（Heathcote et al., 2015）。選択的影響テストでは，認知モデルの特定のパラメータに影響すると考えられる実験的な操作をして，実際にパラメータに変化が生じるのかを検討します。この予想された変化をもって，パラメータとモデルの妥当性を示すことができます。例えば，反応時間に関する Drift-Diffusion Modelの妥当性検討では，色識別課題の条件を操作することで，操作に対応したパラメータの変化を確認していたりします(Voss, Rothermund, and Voss , 2004)。</p>
</div>
<div id="引用参考文献" class="section level2">
<h2>引用・参考文献</h2>
<ul>
<li>Busemeyer, J. R., &amp; Diederich, A. (2010). Cognitive Modeling. SAGE.</li>
<li>Heathcote, A., Brown, S. D., &amp; Wagenmakers, E.-J. (2015). An Introduction to Good Practices in Cognitive Modeling. In B. U. Forstmann &amp; E.-J. Wagenmakers (Eds.), An Introduction to Model-Based Cognitive Neuroscience (pp. 25–48). Springer New York.</li>
<li>Palminteri, S., Wyart, V., &amp; Koechlin, E. (2017). The Importance of Falsification in Computational Cognitive Modeling. Trends in Cognitive Sciences, 21(6), 425–433.</li>
<li>Voss, A., Rothermund, K., &amp; Voss, J. (2004). Interpreting the parameters of the diffusion model: an empirical validation. Memory &amp; Cognition, 32(7), 1206–1220.</li>
<li>Wilson, R. C., &amp; Collins, A. G. (2019). Ten simple rules for the computational modeling of behavioral data. eLife, 8. <a href="https://doi.org/10.7554/eLife.49547" class="uri">https://doi.org/10.7554/eLife.49547</a></li>
</ul>
</div>

<footer>
  <p>Copyright &copy; 2013-2020 Yoshihiko Kunisato. All rights reserved </p>
</footer>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
