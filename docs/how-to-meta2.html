<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>ネットワークメタ分析</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link rel="apple-touch-icon" type="image/png" href="/apple-touch-icon-180x180.png">
<link rel="icon" type="image/png" href="/icon-192x192.png">

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


<link rel="stylesheet" href="site_style.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Computational Clinical Psychology Lab</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="research.html">Research</a>
</li>
<li>
  <a href="team.html">Team</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Publications
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="book.html">書籍</a>
    </li>
    <li>
      <a href="articles.html">学術論文</a>
    </li>
    <li>
      <a href="articles-japanese.html">学術論文（日本語）</a>
    </li>
    <li>
      <a href="bulletin.html">紀要論文</a>
    </li>
    <li>
      <a href="presentation.html">国際会議発表</a>
    </li>
    <li>
      <a href="presentation-japanese.html">国内学会・研究会発表</a>
    </li>
  </ul>
</li>
<li>
  <a href="code_tips.html">Code &amp; Tips</a>
</li>
<li>
  <a href="education.html">Education</a>
</li>
<li>
  <a href="news.html">News</a>
</li>
<li>
  <a href="https://kunisatolab.github.io/english/index.html">English</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">ネットワークメタ分析</h1>

</div>


<div id="ネットワークメタ分析" class="section level2">
<h2>ネットワークメタ分析</h2>
<p>治療Aと治療Bを直接比較した臨床試験の効果を統合するときに使用されるのがメタ分析です。ただ，治療Aと治療B，治療Aと治療Cの直接比較はあるけど，治療Bと治療Cを比較した研究はない（もしくは少ない）状況もあります。その場合に，治療Aと治療B，治療Aと治療Cの直接比較の効果から，治療Bと治療Cの間接比較の効果を検討するネットワークメタ分析という方法があります。以下では，ネットワークメタ分析についてまとめています。</p>
<iframe src="//www.slideshare.net/slideshow/embed_code/key/NgwM14uepVnWpc" width="595" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen>
</iframe>
<div style="margin-bottom:5px">
<strong> <a href="//www.slideshare.net/YoshihikoKunisato/ss-125951316" title="ネットワークメタ分析入門" target="_blank">ネットワークメタ分析入門</a> </strong> from <strong><a href="https://www.slideshare.net/YoshihikoKunisato" target="_blank">Senshu University</a></strong>
</div>
<p><br> <br></p>
</div>
<div id="rstanでベイジアンネットワークメタ分析" class="section level2">
<h2>Rstanでベイジアンネットワークメタ分析</h2>
<p>ネットワークメタ分析は，３つ以上の治療の比較が可能なメタ分析です。これまでよく行われていたメタ分析（一対比較のメタ分析）は，２つの治療間の直接比較の結果を統合するものでした（一対比較のベイジアンメタ分析については，<a href="https://kunisatolab.github.io/main/how-to-meta1.html">こちら</a>を参照ください）。一方，ネットワークメタ分析では，３つ以上の治療について，直接的な比較だけでなく，間接的な比較（別の２つ以上の治療薬の効果から，検討されていない２つの治療薬間の差を推定する）も行って，治療効果の統合をします。ネットワークメタ分析の利点としては，以下の３点があります。</p>
<ul>
<li>間接比較ができる</li>
<li>間接と直接比較を統合し，より精度を高められる</li>
<li>複数の治療が比較でき，効果のランキングが作れる</li>
</ul>
<p>ネットワークメタ分析を学ぶ場合，『Network Meta-Analysis for Decision-Making』](<a href="https://www.amazon.co.jp/dp/1118647505/ref=cm_sw_em_r_mt_dp_U_i6l0EbR0Z21F1)は，丁寧な説明がされており，おすすめの書籍です。ただ，記載されているコードはWinBUGSのものです。Mac" class="uri">https://www.amazon.co.jp/dp/1118647505/ref=cm_sw_em_r_mt_dp_U_i6l0EbR0Z21F1)は，丁寧な説明がされており，おすすめの書籍です。ただ，記載されているコードはWinBUGSのものです。Mac</a> &amp; Stanユーザーとしては，WinBUGSはきついので，第2章で紹介されている固定効果モデルのネットワークメタ分析をStanコードで書き直したものを以下で説明します。</p>
<div id="使用するパッケージ" class="section level3">
<h3>使用するパッケージ</h3>
<p>以下のパッケージを使います。これら一式がインストールされたDockerfileも公開しているので，<a href="https://cpp-laboratory.hatenablog.com/entry/2018/12/08/080000">こちらの記事</a>も参照ください。</p>
<pre class="r"><code>library(rstan)
library(tidybayes)
library(tidyverse)
library(bayesplot)
library(loo)
library(gemtc)
library(gridExtra)</code></pre>
</div>
<div id="データ" class="section level3">
<h3>データ</h3>
<p>使用するのは，『Network Meta-Analysis for Decision-Making』の２章で紹介されている血栓溶解薬のデータです(Caldwell et la., 2005のデータ)。７つの治療薬について検討した36試験のデータです。</p>
<p>変数名について説明します。studyは研究のID，treatmentは治療の種類，deadは死者数，sampleSizeはその治療に参加した患者数です。baselineは，当該試験のベースラインとなる治療です(今回，SKをリファレンスの治療にします。多く試験ではSKがベースラインになりますが，SKが含まれない試験もあり，その場合は他の薬剤がベースラインになります)。treatmentNameは治療薬名，studyNameは第1著者の姓か研究プロジェクト名， studyYearは論文の出版年です。治療の種類のtreatmentと治療薬名のtreatmentNameの組み合わせは以下になります。</p>
<ul>
<li>0 = SK</li>
<li>1 = t_PA</li>
<li>2 = Acc_t_PA</li>
<li>3 = SK_t_PA</li>
<li>4 = r_PA</li>
<li>5 = TNK</li>
<li>6 = PTCA</li>
</ul>
<p>以下を実行して，Rにデータを読み込んでみましょう！</p>
<pre class="r"><code>study &lt;- c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,1)

treatment &lt;- c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,1,1,1,1,1,1,3,4,6,6,6,6,6,6,6,6,6,6,6,4,4,5,6,6,6,6,6,6,6,6,6,6,6,3)

dead &lt;- c(1472,3,12,7,10,887,5,1455,9,4,285,11,1,8,1,4,14,9,42,2,13,2,13,356,522,3,10,40,5,5,2,19,59,5,16,8,652,3,7,4,5,929,2,1418,6,6,270,2,3,5,1,0,7,3,29,3,5,2,7,757,523,1,3,32,5,3,3,20,52,2,12,6,723)

sampleSize &lt;- c(20251,65,159,85,135,10396,63,13780,130,107,3004,149,50,58,53,45,99,41,421,44,200,56,155,4921,8488,55,94,573,75,69,61,419,782,81,226,66,10396,64,157,86,135,10372,59,13746,123,109,3006,152,50,54,47,42,101,46,429,46,195,47,169,10138,8461,55,95,565,75,71,62,421,790,81,225,71,10374)

baseline &lt;- c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,0)

treatmentName &lt;- c(&quot;SK&quot;,&quot;SK&quot;,&quot;SK&quot;,&quot;SK&quot;,&quot;SK&quot;,&quot;SK&quot;,&quot;SK&quot;,&quot;SK&quot;,&quot;SK&quot;,&quot;SK&quot;,&quot;SK&quot;,&quot;SK&quot;,&quot;SK&quot;,&quot;SK&quot;,&quot;SK&quot;,&quot;SK&quot;,&quot;SK&quot;,&quot;SK&quot;,&quot;SK&quot;,&quot;t_PA&quot;,&quot;t_PA&quot;,&quot;t_PA&quot;,&quot;Acc_t_PA&quot;,&quot;Acc_t_PA&quot;,&quot;Acc_t_PA&quot;,&quot;Acc_t_PA&quot;,&quot;Acc_t_PA&quot;,&quot;Acc_t_PA&quot;,&quot;Acc_t_PA&quot;,&quot;Acc_t_PA&quot;,&quot;Acc_t_PA&quot;,&quot;Acc_t_PA&quot;,&quot;Acc_t_PA&quot;,&quot;Acc_t_PA&quot;,&quot;Acc_t_PA&quot;,&quot;Acc_t_PA&quot;,&quot;Acc_t_PA&quot;,&quot;t_PA&quot;,&quot;t_PA&quot;,&quot;t_PA&quot;,&quot;t_PA&quot;,&quot;t_PA&quot;,&quot;t_PA&quot;,&quot;t_PA&quot;,&quot;t_PA&quot;,&quot;SK_t_PA&quot;,&quot;r_PA&quot;,&quot;PTCA&quot;,&quot;PTCA&quot;,&quot;PTCA&quot;,&quot;PTCA&quot;,&quot;PTCA&quot;,&quot;PTCA&quot;,&quot;PTCA&quot;,&quot;PTCA&quot;,&quot;PTCA&quot;,&quot;PTCA&quot;,&quot;PTCA&quot;,&quot;r_PA&quot;,&quot;r_PA&quot;,&quot;TNK&quot;,&quot;PTCA&quot;,&quot;PTCA&quot;,&quot;PTCA&quot;,&quot;PTCA&quot;,&quot;PTCA&quot;,&quot;PTCA&quot;,&quot;PTCA&quot;,&quot;PTCA&quot;,&quot;PTCA&quot;,&quot;PTCA&quot;,&quot;PTCA&quot;,&quot;SK_t_PA&quot;)

studyName &lt;- c(&quot;GUSTO-1&quot;,&quot;ECSG&quot;,&quot;TIMI-1&quot;,&quot;PAIMS&quot;,&quot;White&quot;,&quot;GISSI-2&quot;,&quot;Cherng&quot;,&quot;ISIS-3&quot;,&quot;CI&quot;,&quot;KAMIT&quot;,&quot;INJECT&quot;,&quot;Zijlstra&quot;,&quot;Riberio&quot;,&quot;Grinfeld&quot;,&quot;Zijlstra&quot;,&quot;Akhras&quot;,&quot;Widimsky&quot;,&quot;DeBoer&quot;,&quot;Widimsky&quot;,&quot;DeWood&quot;,&quot;Grines&quot;,&quot;Gibbons&quot;,&quot;RAPID-2&quot;,&quot;GUSTO-3&quot;,&quot;ASSENT-2&quot;,&quot;Ribichini&quot;,&quot;Garcia&quot;,&quot;GUSTO-2&quot;,&quot;Vermeer&quot;,&quot;Schomig&quot;,&quot;LeMay&quot;,&quot;Bonnefoy&quot;,&quot;Andersen&quot;,&quot;Kastrati&quot;,&quot;Aversano&quot;,&quot;Grines&quot;,&quot;GUSTO-1&quot;,&quot;ECSG&quot;,&quot;TIMI-1&quot;,&quot;PAIMS&quot;,&quot;White&quot;,&quot;GISSI-2&quot;,&quot;Cherng&quot;,&quot;ISIS-3&quot;,&quot;CI&quot;,&quot;KAMIT&quot;,&quot;INJECT&quot;,&quot;Zijlstra&quot;,&quot;Riberio&quot;,&quot;Grinfeld&quot;,&quot;Zijlstra&quot;,&quot;Akhras&quot;,&quot;Widimsky&quot;,&quot;DeBoer&quot;,&quot;Widimsky&quot;,&quot;DeWood&quot;,&quot;Grines&quot;,&quot;Gibbons&quot;,&quot;RAPID-2&quot;,&quot;GUSTO-3&quot;,&quot;ASSENT-2&quot;,&quot;Ribichini&quot;,&quot;Garcia&quot;,&quot;GUSTO-2&quot;,&quot;Vermeer&quot;,&quot;Schomig&quot;,&quot;LeMay&quot;,&quot;Bonnefoy&quot;,&quot;Andersen&quot;,&quot;Kastrati&quot;,&quot;Aversano&quot;,&quot;Grines&quot;,&quot;GUSTO-1&quot;)

studyYear &lt;- c(1993,1985,1987,1989,1989,1990,1992,1992,1993,1991,1995,1993,1993,1996,1997,1997,2000,2002,2002,1990,1993,1993,1996,1997,1999,1996,1997,1997,1999,2000,2001,2002,2002,2002,2002,2002,1993,1985,1987,1989,1989,1990,1992,1992,1993,1991,1995,1993,1993,1996,1997,1997,2000,2002,2002,1990,1993,1993,1996,1997,1999,1996,1997,1997,1999,2000,2001,2002,2002,2002,2002,2002,1993)

# データフレームにして確認
data_net &lt;- tibble(study,treatment,dead,sampleSize,baseline,treatmentName,studyName,studyYear)
data_net</code></pre>
<pre><code>## # A tibble: 73 x 8
##    study treatment  dead sampleSize baseline treatmentName studyName studyYear
##    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;         &lt;chr&gt;         &lt;dbl&gt;
##  1     1         0  1472      20251        0 SK            GUSTO-1        1993
##  2     2         0     3         65        0 SK            ECSG           1985
##  3     3         0    12        159        0 SK            TIMI-1         1987
##  4     4         0     7         85        0 SK            PAIMS          1989
##  5     5         0    10        135        0 SK            White          1989
##  6     6         0   887      10396        0 SK            GISSI-2        1990
##  7     7         0     5         63        0 SK            Cherng         1992
##  8     8         0  1455      13780        0 SK            ISIS-3         1992
##  9     9         0     9        130        0 SK            CI             1993
## 10    10         0     4        107        0 SK            KAMIT          1991
## # … with 63 more rows</code></pre>
<p>今回のデータのネットワークを書いてみます。以降では，基本的にはStanを使いますが，ネットワークは，JAGSベースのネットワークメタ分析するGeMTCパッケージを使うと簡単にプロットしてくれます。これは便利なパッケージですが，今回はプロットだけに使います。GeMTC用に少しデータセットを変えて，mtc.network()で読み込み，プロットします。</p>
<pre class="r"><code>data_net &lt;- data.frame(study,treatmentName,dead,sampleSize)
names(data_net) &lt;- c(&quot;study&quot;,&quot;treatment&quot;,&quot;responders&quot;,&quot;sampleSize&quot;)
data_net_GeM &lt;- mtc.network(data_net)
plot(data_net_GeM)</code></pre>
<p><img src="how-to-meta2_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>以下のような感じです。ネットワークのノード（丸と丸をつなぐ線です）が太いほど，試験数が多いことを表しています。これをみると，SKは他の多くの治療薬と直接的に比較されていますが，TNKはSKとは直接的な比較がなされていないことが分かります。</p>
</div>
<div id="ネットワークメタ分析固定効果モデルのstanコード" class="section level3">
<h3>ネットワークメタ分析(固定効果モデル)のStanコード</h3>
<p>まず，data{}ブロックにおいて，使用するデータの定義をしています。教科書は行列形式でdeadやsampleSizeを読み込む形式ですが，少し今後の拡張を考えると面倒です(WinBUGSでやりやすいこととStanでやりやすいことは微妙に違ったりします)。まずlong型のデータセットにしてから（上記のデータはすでにそうなっています），各列をStanに読み込ませます。</p>
<p>parameters{}ブロックでは，推定するパラメータとして，mu(各研究におけるベースライン，リファレンスのSKのときもあれば他の治療の時もあります)とd(各治療におけるベースラインに対する相対効果)を準備しています。</p>
<p>model{}ブロックでは，死者数が二項分布に従うとして，死者数が，binomial_logit(試験の参加人数，死亡確率を構成する式)から生成されます。その場合の，死亡確率を構成する式（線形予測子）には，４つのパターンがあります。</p>
<ol style="list-style-type: decimal">
<li>ベースラインがリファレンス(SK)でかつ，その治療がSKの時，線形予測子は，muのみ</li>
<li>ベースラインがリファレンス(SK)でかつ，その治療がSK以外の時，線形予測子は，mu+d</li>
<li>ベースラインがリファレンス(SK)以外でかつ，その治療がベースラインの治療の時，線形予測子は，muのみ</li>
<li>ベースラインがリファレンス(SK)以外でかつ，その治療がベースライン以外の時，線形予測子は，mu+d(当該治療)-d(ベースライン)</li>
</ol>
<p>四番目が間接比較になります。ネットワークメタ分析では，リファレンスに対する相対効果を推定することで，最終的にランキングなどを作ることができます。この相対効果がdになります。ただ，すべての治療がリファレンスと比較されているわけではないので，間接比較が必要になります。例えば，TNKは，Acc_t_PAとのみ比較をしていますので，間接比較によって，リファレンス(SK)と比較した際のTNKの相対効果も推定する必要があります。TNKによる死亡率は，mu+d(Acc_t_PA→TNK)で計算されます。ただ，今回は，リファレンスからのTNKの相対効果を推定したいので，d(Acc_t_PA→TNK)を，d(SK→TNK)からd(SK→Acc_t_PA)を引くことで計算します（これが上記のd(当該治療)-d(ベースライン)に相当します）。こういう感じで，間接効果も組み込んだ生成モデルを作ることで，間接効果の推定を行います。</p>
<p>なお，dとmuの事前分布としては，幅のひろーい正規分布としました。</p>
<p>generated quantities{}ブロックでは，exp()でdのオッズ比を計算しているのですが，dの可能な組み合わせすべての計算をしています（実際に検討されてない治療間の相対効果も計算している）。その計算が，どうにもStanでスマートにできなかったので，べた書きしています・・・（今後変更できるなら，変更したいです）。最後に，モデル比較用の対数尤度(log_lik)も計算しています。</p>
<p>以下のStanコードを“netmeta_network_fixed_effect.stan”という名前で保存します。</p>
<pre><code>data{
  int ld;             // length of data
  int nct;            // number of compared treatment
  int ns;             // number of study
  int study[ld];      // vector of the study id 
  int treatment[ld];  // vector of the treatment id
  int dead[ld];       // vector of the number of dead
  int sampleSize[ld]; // vector of the number of patient
  int baseline[ld];   // vector of baseline treatment each study
}
parameters{
  real d[nct];
  real mu[ns];
}
model{
  for(i in 1:ld){
    if(baseline[i]==0){
      if(treatment[i]==0){
        dead[i] ~ binomial_logit(sampleSize[i],mu[study[i]]);
      }else{
        dead[i] ~ binomial_logit(sampleSize[i],mu[study[i]]+d[treatment[i]]);
      }
    }else{
      if(baseline[i]==treatment[i]){
        dead[i] ~ binomial_logit(sampleSize[i],mu[study[i]]);
      }else{
        dead[i] ~ binomial_logit(sampleSize[i],mu[study[i]]+d[treatment[i]]-d[baseline[i]]);
      }
    }
  }
  # prior
  d~normal(0,10000);
  mu~normal(0,10000);
}
generated quantities{
  real OR[21];
  real log_lik[ld];
  OR[1] = exp(d[1]);
  OR[2] = exp(d[2]);
  OR[3] = exp(d[3]);
  OR[4] = exp(d[4]);
  OR[5] = exp(d[5]);
  OR[6] = exp(d[6]);
  OR[7] = exp(d[2]-d[1]);
  OR[8] = exp(d[3]-d[1]);
  OR[9] = exp(d[4]-d[1]);
  OR[10] = exp(d[5]-d[1]);
  OR[11] = exp(d[6]-d[1]);
  OR[12] = exp(d[3]-d[2]);
  OR[13] = exp(d[4]-d[2]);
  OR[14] = exp(d[5]-d[2]);
  OR[15] = exp(d[6]-d[2]);
  OR[16] = exp(d[4]-d[3]);
  OR[17] = exp(d[5]-d[3]);
  OR[18] = exp(d[6]-d[3]);
  OR[19] = exp(d[5]-d[4]);
  OR[20] = exp(d[6]-d[4]);
  OR[21] = exp(d[6]-d[5]);
  
  for(k in 1:ld){
    if(baseline[k]==0){
      if(treatment[k]==0){
        log_lik[k] = binomial_logit_lpmf(dead[k]|sampleSize[k],mu[study[k]]);
      }else{
        log_lik[k] = binomial_logit_lpmf(dead[k]|sampleSize[k],mu[study[k]]+d[treatment[k]]);
      }
    }else{
      if(baseline[k]==treatment[k]){
        log_lik[k] = binomial_logit_lpmf(dead[k]|sampleSize[k],mu[study[k]]);
      }else{
        log_lik[k] = binomial_logit_lpmf(dead[k]|sampleSize[k],mu[study[k]]+d[treatment[k]]-d[baseline[k]]);
      }
    }
  }
}
</code></pre>
</div>
<div id="パラメータ推定" class="section level3">
<h3>パラメータ推定</h3>
<p>Stanコードが書けましたので，早速，コンパイル＆サンプリングをします。</p>
<pre class="r"><code>ld = length(study)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
options(max.print = 99999)
fit_fixed_net &lt;-stan(&quot;netmeta_network_fixed_effect.stan&quot;,data=list(ld = ld, nct = 6, ns = 36, study = study, treatment = treatment, dead = dead, sampleSize = sampleSize,baseline=baseline), chains = 4, iter = 5500, warmup = 500, thin = 1)</code></pre>
</div>
<div id="推定結果の要約" class="section level3">
<h3>推定結果の要約</h3>
<p>結果を簡単に確認します。</p>
<pre class="r"><code>print(fit_fixed_net,digit=4)</code></pre>
<pre><code>## Inference for Stan model: netmeta_network_fixed_effect.
## 4 chains, each with iter=5500; warmup=500; thin=1; 
## post-warmup draws per chain=5000, total post-warmup draws=20000.
## 
##                    mean se_mean     sd        2.5%         25%         50%
## d[1]            -0.0032  0.0002 0.0305     -0.0633     -0.0235     -0.0031
## d[2]            -0.1573  0.0003 0.0435     -0.2427     -0.1865     -0.1574
## d[3]            -0.0431  0.0003 0.0463     -0.1336     -0.0740     -0.0429
## d[4]            -0.1104  0.0004 0.0605     -0.2281     -0.1520     -0.1107
## d[5]            -0.1510  0.0005 0.0784     -0.3051     -0.2029     -0.1512
## d[6]            -0.4746  0.0007 0.1009     -0.6726     -0.5422     -0.4749
## mu[1]           -2.5475  0.0002 0.0259     -2.5980     -2.5649     -2.5475
## mu[2]           -3.1005  0.0023 0.4336     -4.0274     -3.3722     -3.0725
## mu[3]           -2.7742  0.0012 0.2412     -3.2780     -2.9302     -2.7644
## mu[4]           -2.7208  0.0016 0.3212     -3.4050     -2.9280     -2.7071
## mu[5]           -2.8631  0.0014 0.2719     -3.4268     -3.0417     -2.8530
## mu[6]           -2.3439  0.0002 0.0287     -2.4007     -2.3631     -2.3440
## mu[7]           -2.8653  0.0020 0.4026     -3.7279     -3.1203     -2.8414
## mu[8]           -2.1483  0.0001 0.0249     -2.1970     -2.1652     -2.1482
## mu[9]           -2.7943  0.0013 0.2729     -3.3581     -2.9684     -2.7855
## mu[10]          -3.0542  0.0017 0.3328     -3.7467     -3.2686     -3.0377
## mu[11]          -2.2324  0.0003 0.0530     -2.3362     -2.2680     -2.2320
## mu[12]          -2.9226  0.0015 0.2895     -3.5238     -3.1110     -2.9088
## mu[13]          -3.0914  0.0029 0.5359     -4.2486     -3.4207     -3.0514
## mu[14]          -1.8539  0.0015 0.3032     -2.4813     -2.0533     -1.8417
## mu[15]          -3.9651  0.0050 0.8130     -5.8315     -4.4314     -3.8643
## mu[16]          -2.9517  0.0031 0.5523     -4.1548     -3.2979     -2.9075
## mu[17]          -1.9496  0.0012 0.2391     -2.4355     -2.1084     -1.9426
## mu[18]          -1.6375  0.0016 0.3216     -2.2996     -1.8469     -1.6279
## mu[19]          -2.1857  0.0007 0.1304     -2.4467     -2.2728     -2.1841
## mu[20]          -2.7161  0.0025 0.4831     -3.7643     -3.0176     -2.6856
## mu[21]          -2.8622  0.0012 0.2485     -3.3741     -3.0260     -2.8543
## mu[22]          -3.1421  0.0029 0.5439     -4.3305     -3.4743     -3.0964
## mu[23]          -2.7702  0.0011 0.2285     -3.2347     -2.9219     -2.7633
## mu[24]          -2.5605  0.0003 0.0488     -2.6562     -2.5932     -2.5603
## mu[25]          -2.7264  0.0002 0.0458     -2.8178     -2.7574     -2.7260
## mu[26]          -3.2604  0.0031 0.5481     -4.4468     -3.5964     -3.2197
## mu[27]          -2.4948  0.0014 0.2957     -3.1031     -2.6872     -2.4817
## mu[28]          -2.5555  0.0007 0.1299     -2.8121     -2.6422     -2.5545
## mu[29]          -2.5397  0.0017 0.3391     -3.2440     -2.7590     -2.5264
## mu[30]          -2.7160  0.0019 0.3804     -3.5193     -2.9580     -2.6976
## mu[31]          -3.1156  0.0026 0.4887     -4.1730     -3.4254     -3.0789
## mu[32]          -2.8889  0.0008 0.1715     -3.2339     -3.0019     -2.8859
## mu[33]          -2.4339  0.0006 0.1076     -2.6503     -2.5055     -2.4326
## mu[34]          -3.0189  0.0021 0.3990     -3.8725     -3.2705     -2.9966
## mu[35]          -2.5859  0.0010 0.1999     -2.9996     -2.7165     -2.5800
## mu[36]          -2.0511  0.0015 0.2938     -2.6618     -2.2424     -2.0414
## OR[1]            0.9973  0.0002 0.0304      0.9387      0.9768      0.9969
## OR[2]            0.8552  0.0003 0.0372      0.7845      0.8299      0.8544
## OR[3]            0.9588  0.0003 0.0444      0.8749      0.9286      0.9580
## OR[4]            0.8971  0.0004 0.0544      0.7960      0.8590      0.8952
## OR[5]            0.8625  0.0004 0.0677      0.7370      0.8164      0.8597
## OR[6]            0.6253  0.0004 0.0633      0.5104      0.5815      0.6219
## OR[7]            0.8584  0.0003 0.0455      0.7730      0.8269      0.8570
## OR[8]            0.9623  0.0003 0.0531      0.8625      0.9262      0.9613
## OR[9]            0.9004  0.0004 0.0608      0.7865      0.8580      0.8981
## OR[10]           0.8656  0.0005 0.0729      0.7322      0.8149      0.8621
## OR[11]           0.6275  0.0004 0.0660      0.5089      0.5819      0.6237
## OR[12]           1.1226  0.0003 0.0608      1.0073      1.0812      1.1213
## OR[13]           1.0497  0.0003 0.0582      0.9411      1.0097      1.0477
## OR[14]           1.0084  0.0004 0.0653      0.8859      0.9634      1.0068
## OR[15]           0.7316  0.0005 0.0719      0.6006      0.6815      0.7282
## OR[16]           0.9373  0.0004 0.0668      0.8134      0.8913      0.9350
## OR[17]           0.9009  0.0004 0.0764      0.7628      0.8479      0.8974
## OR[18]           0.6533  0.0004 0.0701      0.5280      0.6039      0.6498
## OR[19]           0.9636  0.0005 0.0820      0.8121      0.9067      0.9608
## OR[20]           0.6990  0.0005 0.0775      0.5595      0.6451      0.6949
## OR[21]           0.7285  0.0005 0.0857      0.5738      0.6689      0.7235
## log_lik[1]      -4.9879  0.0057 0.6532     -6.8483     -5.1407     -4.7348
## log_lik[2]      -1.7278  0.0042 0.3596     -2.7436     -1.8115     -1.5868
## log_lik[3]      -2.7545  0.0058 0.7397     -4.8066     -3.0212     -2.4930
## log_lik[4]      -2.3962  0.0056 0.6648     -4.2917     -2.6190     -2.1525
## log_lik[5]      -2.7729  0.0064 0.8162     -4.9778     -3.1084     -2.5001
## log_lik[6]      -4.9378  0.0061 0.8308     -7.2634     -5.2207     -4.6276
## log_lik[7]      -2.3081  0.0061 0.7394     -4.3708     -2.5662     -2.0383
## log_lik[8]      -4.9913  0.0056 0.6790     -6.9136     -5.1651     -4.7293
## log_lik[9]      -2.4042  0.0051 0.5539     -3.9560     -2.5496     -2.1948
## log_lik[10]     -1.9433  0.0039 0.4456     -3.2036     -2.0611     -1.7717
## log_lik[11]     -4.1338  0.0049 0.6032     -5.8388     -4.2844     -3.8977
## log_lik[12]     -3.0925  0.0078 1.0742     -5.9288     -3.5541     -2.7509
## log_lik[13]     -1.6929  0.0043 0.7504     -3.7032     -2.0147     -1.4517
## log_lik[14]     -2.2059  0.0052 0.4338     -3.4532     -2.3093     -2.0378
## log_lik[15]     -1.2968  0.0046 0.4302     -2.5308     -1.3960     -1.1283
## log_lik[16]     -2.5039  0.0088 1.0631     -5.4081     -2.9160     -2.1301
## log_lik[17]     -2.5991  0.0056 0.5861     -4.2611     -2.7516     -2.3725
## log_lik[18]     -2.6347  0.0067 0.8490     -4.9408     -2.9564     -2.3404
## log_lik[19]     -3.0654  0.0051 0.4652     -4.3678     -3.1712     -2.8885
## log_lik[20]     -1.6905  0.0043 0.5404     -3.2218     -1.8375     -1.4796
## log_lik[21]     -2.7095  0.0059 0.6949     -4.6752     -2.9217     -2.4467
## log_lik[22]     -1.6330  0.0048 0.4902     -3.0236     -1.7453     -1.4432
## log_lik[23]     -3.1599  0.0060 0.9327     -5.5420     -3.6173     -2.9106
## log_lik[24]     -4.2229  0.0055 0.5665     -5.8258     -4.3586     -4.0032
## log_lik[25]     -4.5297  0.0077 0.7206     -6.5823     -4.6950     -4.2496
## log_lik[26]     -1.9658  0.0066 0.6597     -3.8166     -2.1472     -1.7116
## log_lik[27]     -2.8549  0.0070 0.9309     -5.3277     -3.2321     -2.5438
## log_lik[28]     -3.0743  0.0051 0.4911     -4.4544     -3.1845     -2.8892
## log_lik[29]     -2.0191  0.0047 0.4413     -3.2665     -2.1206     -1.8480
## log_lik[30]     -2.0505  0.0052 0.4878     -3.4273     -2.1639     -1.8639
## log_lik[31]     -1.6574  0.0045 0.5041     -3.0886     -1.7849     -1.4612
## log_lik[32]     -2.9171  0.0051 0.6823     -4.8267     -3.1493     -2.6571
## log_lik[33]     -3.3992  0.0055 0.6465     -5.2394     -3.5701     -3.1521
## log_lik[34]     -2.1815  0.0062 0.6319     -3.9832     -2.3525     -1.9392
## log_lik[35]     -2.5680  0.0047 0.4123     -3.7895     -2.6637     -2.4078
## log_lik[36]     -2.2067  0.0050 0.4250     -3.4197     -2.3032     -2.0431
## log_lik[37]     -4.5563  0.0052 0.6140     -6.3314     -4.6859     -4.3197
## log_lik[38]     -1.7274  0.0042 0.3597     -2.7444     -1.8115     -1.5874
## log_lik[39]     -2.4335  0.0043 0.6345     -4.1651     -2.6757     -2.2167
## log_lik[40]     -2.0457  0.0044 0.5533     -3.5997     -2.2248     -1.8415
## log_lik[41]     -2.3916  0.0043 0.7087     -4.2917     -2.6969     -2.1659
## log_lik[42]     -4.9634  0.0060 0.8309     -7.2807     -5.2461     -4.6570
## log_lik[43]     -1.7914  0.0038 0.5841     -3.3992     -2.0068     -1.5896
## log_lik[44]     -4.9719  0.0061 0.6738     -6.9082     -5.1214     -4.7146
## log_lik[45]     -2.1401  0.0040 0.4635     -3.4403     -2.2556     -1.9637
## log_lik[46]     -2.2181  0.0052 0.5523     -3.7596     -2.3736     -2.0068
## log_lik[47]     -4.1082  0.0053 0.6026     -5.8077     -4.2565     -3.8813
## log_lik[48]     -2.6536  0.0046 0.9077     -4.8421     -3.1517     -2.4899
## log_lik[49]     -2.3985  0.0066 0.9093     -4.7631     -2.8174     -2.1487
## log_lik[50]     -1.9021  0.0034 0.2947     -2.7399     -1.9701     -1.7891
## log_lik[51]     -1.3135  0.0042 0.4355     -2.5614     -1.4290     -1.1455
## log_lik[52]     -1.5369  0.0039 0.7930     -3.4291     -1.9717     -1.3997
## log_lik[53]     -2.1927  0.0035 0.4338     -3.4109     -2.3104     -2.0253
## log_lik[54]     -2.1898  0.0041 0.7145     -4.0327     -2.5229     -1.9869
## log_lik[55]     -2.8399  0.0040 0.3788     -3.8943     -2.9290     -2.6951
## log_lik[56]     -1.9996  0.0053 0.6334     -3.7541     -2.2286     -1.7758
## log_lik[57]     -2.1820  0.0036 0.5294     -3.6144     -2.3831     -1.9968
## log_lik[58]     -1.6676  0.0043 0.4838     -3.0035     -1.8203     -1.4870
## log_lik[59]     -2.8043  0.0057 0.8627     -5.0149     -3.2208     -2.5752
## log_lik[60]     -4.6407  0.0058 0.6328     -6.4417     -4.7812     -4.3978
## log_lik[61]     -4.5186  0.0065 0.7251     -6.5935     -4.6679     -4.2423
## log_lik[62]     -1.3018  0.0033 0.4179     -2.4906     -1.4131     -1.1429
## log_lik[63]     -2.3643  0.0044 0.7805     -4.3544     -2.7484     -2.1656
## log_lik[64]     -2.9392  0.0040 0.4319     -4.1515     -3.0452     -2.7729
## log_lik[65]     -2.0329  0.0043 0.4423     -3.2958     -2.1486     -1.8633
## log_lik[66]     -1.7109  0.0034 0.3318     -2.6610     -1.7887     -1.5838
## log_lik[67]     -1.9501  0.0053 0.5977     -3.6224     -2.1498     -1.7263
## log_lik[68]     -3.0247  0.0051 0.7164     -4.9301     -3.3112     -2.7761
## log_lik[69]     -3.3814  0.0050 0.6529     -5.2343     -3.5938     -3.1363
## log_lik[70]     -1.6320  0.0033 0.4342     -2.8303     -1.7626     -1.4702
## log_lik[71]     -2.3763  0.0036 0.3299     -3.3432     -2.4509     -2.2473
## log_lik[72]     -2.0265  0.0039 0.3392     -2.9759     -2.1072     -1.8944
## log_lik[73]     -4.6741  0.0065 0.7005     -6.6392     -4.8427     -4.4039
## lp__        -37607.7094  0.0538 4.6400 -37617.7498 -37610.6264 -37607.4029
##                     75%       97.5% n_eff   Rhat
## d[1]             0.0174      0.0559 25847 0.9999
## d[2]            -0.1279     -0.0719 21740 1.0001
## d[3]            -0.0120      0.0467 31514 1.0000
## d[4]            -0.0696      0.0088 23640 1.0000
## d[5]            -0.0987      0.0040 24617 1.0000
## d[6]            -0.4066     -0.2779 23108 1.0000
## mu[1]           -2.5302     -2.4970 22983 0.9999
## mu[2]           -2.7980     -2.3191 35255 0.9999
## mu[3]           -2.6074     -2.3253 42277 0.9998
## mu[4]           -2.4982     -2.1268 42873 0.9999
## mu[5]           -2.6734     -2.3579 38152 0.9999
## mu[6]           -2.3244     -2.2873 29746 0.9999
## mu[7]           -2.5875     -2.1408 39791 1.0000
## mu[8]           -2.1314     -2.0998 28295 0.9999
## mu[9]           -2.6066     -2.2891 41867 0.9999
## mu[10]          -2.8211     -2.4512 39418 0.9999
## mu[11]          -2.1959     -2.1298 28260 0.9999
## mu[12]          -2.7221     -2.3925 39347 0.9999
## mu[13]          -2.7125     -2.1605 33479 1.0000
## mu[14]          -1.6437     -1.2902 40479 1.0000
## mu[15]          -3.3971     -2.6436 26651 1.0000
## mu[16]          -2.5610     -1.9910 32003 1.0000
## mu[17]          -1.7835     -1.5038 41441 0.9999
## mu[18]          -1.4116     -1.0453 39995 0.9999
## mu[19]          -2.0968     -1.9357 38837 0.9999
## mu[20]          -2.3785     -1.8635 35986 1.0000
## mu[21]          -2.6897     -2.3989 42399 0.9999
## mu[22]          -2.7602     -2.1989 34639 0.9999
## mu[23]          -2.6119     -2.3447 42258 0.9998
## mu[24]          -2.5273     -2.4650 32637 0.9999
## mu[25]          -2.6955     -2.6372 36395 1.0000
## mu[26]          -2.8760     -2.3042 31722 0.9998
## mu[27]          -2.2883     -1.9561 43230 0.9998
## mu[28]          -2.4659     -2.3075 39330 0.9999
## mu[29]          -2.3056     -1.9227 39608 0.9999
## mu[30]          -2.4509     -2.0288 41520 1.0000
## mu[31]          -2.7722     -2.2562 34258 0.9999
## mu[32]          -2.7699     -2.5645 41735 0.9998
## mu[33]          -2.3605     -2.2263 34800 0.9999
## mu[34]          -2.7387     -2.3028 36891 0.9999
## mu[35]          -2.4475     -2.2107 39848 0.9999
## mu[36]          -1.8462     -1.5077 38588 0.9999
## OR[1]            1.0175      1.0575 25779 0.9999
## OR[2]            0.8799      0.9307 21762 1.0001
## OR[3]            0.9881      1.0478 31434 1.0000
## OR[4]            0.9328      1.0088 23507 1.0000
## OR[5]            0.9061      1.0041 24440 1.0000
## OR[6]            0.6659      0.7574 22854 1.0000
## OR[7]            0.8884      0.9511 22722 1.0000
## OR[8]            0.9965      1.0702 29228 0.9999
## OR[9]            0.9399      1.0250 23166 1.0000
## OR[10]           0.9127      1.0173 24610 1.0000
## OR[11]           0.6699      0.7658 22986 1.0000
## OR[12]           1.1629      1.2446 37575 0.9999
## OR[13]           1.0879      1.1681 28693 0.9999
## OR[14]           1.0511      1.1427 29893 0.9999
## OR[15]           0.7782      0.8823 24595 1.0000
## OR[16]           0.9802      1.0738 32781 0.9999
## OR[17]           0.9503      1.0608 32016 0.9999
## OR[18]           0.6984      0.8007 26958 0.9999
## OR[19]           1.0166      1.1348 30161 0.9999
## OR[20]           0.7482      0.8628 25662 1.0000
## OR[21]           0.7828      0.9102 27141 1.0000
## log_lik[1]      -4.5740     -4.5289 13277 1.0001
## log_lik[2]      -1.4995     -1.4726  7205 1.0001
## log_lik[3]      -2.2236     -2.1301 16295 1.0002
## log_lik[4]      -1.9292     -1.8615 14078 0.9999
## log_lik[5]      -2.1682     -2.0415 16325 0.9999
## log_lik[6]      -4.3537     -4.2693 18736 1.0000
## log_lik[7]      -1.7854     -1.6999 14732 1.0004
## log_lik[8]      -4.5553     -4.5052 14592 1.0000
## log_lik[9]      -2.0379     -1.9914 11591 1.0000
## log_lik[10]     -1.6495     -1.6142 13103 1.0001
## log_lik[11]     -3.7414     -3.6961 14950 0.9999
## log_lik[12]     -2.2868     -2.0894 19106 0.9999
## log_lik[13]     -1.1294     -0.9914 30080 0.9999
## log_lik[14]     -1.9282     -1.8954  6888 1.0007
## log_lik[15]     -1.0208     -0.9908  8671 1.0005
## log_lik[16]     -1.7253     -1.5878 14528 1.0003
## log_lik[17]     -2.2140     -2.1688 10792 1.0003
## log_lik[18]     -2.0132     -1.9045 16243 1.0001
## log_lik[19]     -2.7704     -2.7376  8440 1.0002
## log_lik[20]     -1.3283     -1.2841 15852 1.0002
## log_lik[21]     -2.2358     -2.1748 13657 1.0000
## log_lik[22]     -1.3243     -1.2891 10393 1.0006
## log_lik[23]     -2.4419     -2.1692 23927 0.9999
## log_lik[24]     -3.8604     -3.8195 10564 1.0003
## log_lik[25]     -4.0690     -4.0167  8793 1.0004
## log_lik[26]     -1.5247     -1.4685 10012 1.0000
## log_lik[27]     -2.1622     -2.0239 17905 0.9999
## log_lik[28]     -2.7636     -2.7296  9410 1.0001
## log_lik[29]     -1.7373     -1.7061  8936 1.0003
## log_lik[30]     -1.7394     -1.7031  8636 1.0004
## log_lik[31]     -1.3287     -1.2907 12643 1.0003
## log_lik[32]     -2.4390     -2.3730 18148 0.9999
## log_lik[33]     -2.9721     -2.9204 13771 1.0004
## log_lik[34]     -1.7621     -1.7090 10432 1.0003
## log_lik[35]     -2.3035     -2.2740  7843 1.0008
## log_lik[36]     -1.9361     -1.9049  7106 1.0002
## log_lik[37]     -4.1707     -4.1271 13958 1.0001
## log_lik[38]     -1.4993     -1.4722  7222 1.0001
## log_lik[39]     -1.9712     -1.8820 21808 1.0000
## log_lik[40]     -1.6625     -1.6097 15467 1.0001
## log_lik[41]     -1.8549     -1.7233 26958 0.9998
## log_lik[42]     -4.3779     -4.2900 19228 0.9999
## log_lik[43]     -1.3690     -1.2906 23286 0.9999
## log_lik[44]     -4.5421     -4.4936 12163 0.9999
## log_lik[45]     -1.8400     -1.8041 13313 0.9999
## log_lik[46]     -1.8476     -1.8009 11411 1.0001
## log_lik[47]     -3.7185     -3.6719 12757 1.0003
## log_lik[48]     -1.9709     -1.4118 39045 0.9999
## log_lik[49]     -1.7017     -1.4689 18895 1.0001
## log_lik[50]     -1.7136     -1.6921  7415 1.0004
## log_lik[51]     -1.0242     -0.9897 10618 1.0003
## log_lik[52]     -0.9512     -0.4117 40588 0.9999
## log_lik[53]     -1.9037     -1.8683 15189 1.0000
## log_lik[54]     -1.6488     -1.4648 29826 0.9999
## log_lik[55]     -2.5980     -2.5708  8964 1.0000
## log_lik[56]     -1.5423     -1.4630 14364 1.0001
## log_lik[57]     -1.7972     -1.7280 21955 1.0000
## log_lik[58]     -1.3342     -1.2857 12488 1.0004
## log_lik[59]     -2.1454     -1.8877 23200 0.9998
## log_lik[60]     -4.2410     -4.1954 12012 1.0000
## log_lik[61]     -4.0676     -4.0176 12362 1.0000
## log_lik[62]     -1.0257     -0.9912 15964 1.0001
## log_lik[63]     -1.7733     -1.4868 31027 0.9998
## log_lik[64]     -2.6590     -2.6256 11933 0.9999
## log_lik[65]     -1.7410     -1.7062 10830 1.0001
## log_lik[66]     -1.4988     -1.4746  9431 1.0003
## log_lik[67]     -1.5304     -1.4718 12892 1.0002
## log_lik[68]     -2.4988     -2.3975 19451 1.0000
## log_lik[69]     -2.9283     -2.8629 17172 1.0002
## log_lik[70]     -1.3340     -1.2948 17074 1.0005
## log_lik[71]     -2.1642     -2.1412  8308 1.0005
## log_lik[72]     -1.8088     -1.7849  7487 1.0001
## log_lik[73]     -4.2269     -4.1751 11654 1.0003
## lp__        -37604.4065 -37599.6194  7450 1.0013
## 
## Samples were drawn using NUTS(diag_e) at Thu Dec 24 01:40:37 2020.
## For each parameter, n_eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor on split chains (at 
## convergence, Rhat=1).</code></pre>
<p>見にくいので，一部の結果のみを示します。若干ズレはありますが，教科書とほぼ同じ推定値になりました（関心のあるパラメータのみ掲載）。Rhatやn_effからもサンプリングも問題なさそうです。</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>mean</th>
<th>se_mean</th>
<th>sd</th>
<th>2.5%</th>
<th>97.5%</th>
<th>n_eff</th>
<th>Rhat</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>d[1]</td>
<td>-0.0032</td>
<td>0.0002</td>
<td>0.0304</td>
<td>-0.0627</td>
<td>0.0562</td>
<td>23842</td>
<td>0.9998</td>
</tr>
<tr class="even">
<td>d[2]</td>
<td>-0.1567</td>
<td>0.0003</td>
<td>0.0434</td>
<td>-0.2418</td>
<td>-0.0729</td>
<td>21865</td>
<td>1.0001</td>
</tr>
<tr class="odd">
<td>d[3]</td>
<td>-0.0430</td>
<td>0.0003</td>
<td>0.0465</td>
<td>-0.1334</td>
<td>0.0465</td>
<td>28616</td>
<td>1.0000</td>
</tr>
<tr class="even">
<td>d[4]</td>
<td>-0.1106</td>
<td>0.0004</td>
<td>0.0601</td>
<td>-0.2289</td>
<td>0.0053</td>
<td>23642</td>
<td>1.0000</td>
</tr>
<tr class="odd">
<td>d[5]</td>
<td>-0.1517</td>
<td>0.0005</td>
<td>0.0763</td>
<td>-0.3028</td>
<td>-0.0022</td>
<td>22117</td>
<td>1.0000</td>
</tr>
<tr class="even">
<td>d[6]</td>
<td>-0.4746</td>
<td>0.0006</td>
<td>0.0998</td>
<td>-0.6720</td>
<td>-0.2797</td>
<td>23850</td>
<td>0.9999</td>
</tr>
</tbody>
</table>
<p>なお，収束判定は以下のようなコードで可視化できます。R hat，トレースプロット，自己相関，有効サンプルサイズの順番です。</p>
<pre class="r"><code>stan_rhat(fit_fixed_net, pars = c(&quot;mu&quot;))</code></pre>
<p><img src="how-to-meta2_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<pre class="r"><code>stan_trace(fit_fixed_net, pars = c(&quot;mu&quot;),inc_warmup=T)</code></pre>
<p><img src="how-to-meta2_files/figure-html/unnamed-chunk-6-2.png" width="672" /></p>
<pre class="r"><code>stan_ac(fit_fixed_net, pars = c(&quot;mu&quot;))</code></pre>
<p><img src="how-to-meta2_files/figure-html/unnamed-chunk-6-3.png" width="672" /></p>
<pre class="r"><code>stan_ess(fit_fixed_net, pars = c(&quot;mu&quot;))</code></pre>
<p><img src="how-to-meta2_files/figure-html/unnamed-chunk-6-4.png" width="672" /></p>
<pre class="r"><code>stan_rhat(fit_fixed_net, pars = c(&quot;d&quot;))</code></pre>
<p><img src="how-to-meta2_files/figure-html/unnamed-chunk-6-5.png" width="672" /></p>
<pre class="r"><code>stan_trace(fit_fixed_net, pars = c(&quot;d&quot;),inc_warmup=T)</code></pre>
<p><img src="how-to-meta2_files/figure-html/unnamed-chunk-6-6.png" width="672" /></p>
<pre class="r"><code>stan_ac(fit_fixed_net, pars = c(&quot;d&quot;))</code></pre>
<p><img src="how-to-meta2_files/figure-html/unnamed-chunk-6-7.png" width="672" /></p>
<pre class="r"><code>stan_ess(fit_fixed_net, pars = c(&quot;d&quot;))</code></pre>
<p><img src="how-to-meta2_files/figure-html/unnamed-chunk-6-8.png" width="672" /></p>
</div>
<div id="各治療のオッズ比" class="section level3">
<h3>各治療のオッズ比</h3>
<p>オッズ比は以下になります。実際は比較してないペアについても，算出できています。</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>pair</th>
<th>mean</th>
<th>se_mean</th>
<th>sd</th>
<th>2.5%</th>
<th>97.5%</th>
<th>n_eff</th>
<th>Rhat</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>OR[1]</td>
<td>SK vs t-PA</td>
<td>0.9973</td>
<td>0.0002</td>
<td>0.0303</td>
<td>0.9392</td>
<td>1.0578</td>
<td>23808</td>
<td>0.9998</td>
</tr>
<tr class="even">
<td>OR[2]</td>
<td>SK vs Acc t-PA</td>
<td>0.8558</td>
<td>0.0003</td>
<td>0.0371</td>
<td>0.7852</td>
<td>0.9297</td>
<td>21908</td>
<td>1.0001</td>
</tr>
<tr class="odd">
<td>OR[3]</td>
<td>SK vs SK+t-PA</td>
<td>0.9589</td>
<td>0.0003</td>
<td>0.0446</td>
<td>0.8752</td>
<td>1.0476</td>
<td>28675</td>
<td>1.0000</td>
</tr>
<tr class="even">
<td>OR[4]</td>
<td>SK vs r-PA</td>
<td>0.8969</td>
<td>0.0004</td>
<td>0.0539</td>
<td>0.7954</td>
<td>1.0053</td>
<td>23613</td>
<td>1.0000</td>
</tr>
<tr class="odd">
<td>OR[5]</td>
<td>SK vs TNK</td>
<td>0.8617</td>
<td>0.0004</td>
<td>0.0658</td>
<td>0.7388</td>
<td>0.9978</td>
<td>22052</td>
<td>1.0000</td>
</tr>
<tr class="even">
<td>OR[6]</td>
<td>SK vs PTCA</td>
<td>0.6252</td>
<td>0.0004</td>
<td>0.0625</td>
<td>0.5107</td>
<td>0.7560</td>
<td>23889</td>
<td>0.9999</td>
</tr>
<tr class="odd">
<td>OR[7]</td>
<td>t-PA vs Acc t-PA</td>
<td>0.8589</td>
<td>0.0003</td>
<td>0.0456</td>
<td>0.7730</td>
<td>0.9516</td>
<td>21996</td>
<td>1.0001</td>
</tr>
<tr class="even">
<td>OR[8]</td>
<td>t-PA vs SK+t-PA</td>
<td>0.9624</td>
<td>0.0003</td>
<td>0.0537</td>
<td>0.8613</td>
<td>1.0717</td>
<td>27188</td>
<td>1.0000</td>
</tr>
<tr class="odd">
<td>OR[9]</td>
<td>t-PA vs r-PA</td>
<td>0.9002</td>
<td>0.0004</td>
<td>0.0608</td>
<td>0.7870</td>
<td>1.0242</td>
<td>22918</td>
<td>1.0000</td>
</tr>
<tr class="even">
<td>OR[10]</td>
<td>t-PA vs TNK</td>
<td>0.8649</td>
<td>0.0005</td>
<td>0.0711</td>
<td>0.7337</td>
<td>1.0101</td>
<td>22062</td>
<td>1.0000</td>
</tr>
<tr class="odd">
<td>OR[11]</td>
<td>t-PA vs PTCA</td>
<td>0.6276</td>
<td>0.0004</td>
<td>0.0657</td>
<td>0.5086</td>
<td>0.7656</td>
<td>23999</td>
<td>0.9999</td>
</tr>
<tr class="even">
<td>OR[12]</td>
<td>Acc t-PA vs SK+t-PA</td>
<td>1.1219</td>
<td>0.0003</td>
<td>0.0600</td>
<td>1.0094</td>
<td>1.2417</td>
<td>36702</td>
<td>0.9998</td>
</tr>
<tr class="odd">
<td>OR[13]</td>
<td>Acc t-PA vs r-PA</td>
<td>1.0487</td>
<td>0.0004</td>
<td>0.0582</td>
<td>0.9396</td>
<td>1.1670</td>
<td>27051</td>
<td>1.0000</td>
</tr>
<tr class="even">
<td>OR[14]</td>
<td>Acc t-PA vs TNK</td>
<td>1.0070</td>
<td>0.0004</td>
<td>0.0638</td>
<td>0.8854</td>
<td>1.1366</td>
<td>28794</td>
<td>0.9999</td>
</tr>
<tr class="odd">
<td>OR[15]</td>
<td>Acc t-PA vs PTCA</td>
<td>0.7311</td>
<td>0.0005</td>
<td>0.0714</td>
<td>0.6010</td>
<td>0.8796</td>
<td>25052</td>
<td>1.0000</td>
</tr>
<tr class="even">
<td>OR[16]</td>
<td>SK+t-PA vs r-PA</td>
<td>0.9370</td>
<td>0.0004</td>
<td>0.0669</td>
<td>0.8132</td>
<td>1.0741</td>
<td>30885</td>
<td>1.0000</td>
</tr>
<tr class="odd">
<td>OR[17]</td>
<td>SK+t-PA vs TNK</td>
<td>0.9000</td>
<td>0.0004</td>
<td>0.0739</td>
<td>0.7635</td>
<td>1.0515</td>
<td>29426</td>
<td>0.9999</td>
</tr>
<tr class="even">
<td>OR[18]</td>
<td>SK+t-PA vs PTCA</td>
<td>0.6532</td>
<td>0.0004</td>
<td>0.0697</td>
<td>0.5261</td>
<td>0.7977</td>
<td>26023</td>
<td>0.9999</td>
</tr>
<tr class="odd">
<td>OR[19]</td>
<td>r-PA vs TNK</td>
<td>0.9631</td>
<td>0.0005</td>
<td>0.0809</td>
<td>0.8148</td>
<td>1.1301</td>
<td>28116</td>
<td>1.0000</td>
</tr>
<tr class="even">
<td>OR[20]</td>
<td>r-PA vs PTCA</td>
<td>0.6991</td>
<td>0.0005</td>
<td>0.0770</td>
<td>0.5612</td>
<td>0.8609</td>
<td>25952</td>
<td>1.0000</td>
</tr>
<tr class="odd">
<td>OR[21]</td>
<td>TNK vs PTCA</td>
<td>0.7290</td>
<td>0.0005</td>
<td>0.0847</td>
<td>0.5774</td>
<td>0.9073</td>
<td>25957</td>
<td>1.0000</td>
</tr>
</tbody>
</table>
<p>オッズ比をプロットすると以下のようになります。</p>
<pre class="r"><code>fit_fixed_net %&gt;% 
  spread_draws(OR[pair]) %&gt;% 
  ggplot(aes(x = OR,y = as.factor(pair))) +
  geom_halfeyeh(.width = .95) +
  ylab(&quot;Treatment&quot;) +
  scale_y_discrete(breaks = c(1, 2, 3, 4,5,6,7,8,9,10,11,12,13,14,15,16,17,
                              18,19,20,21), 
                   labels = c(&quot;SK vs t-PA&quot;,&quot;SK vs Acc t-PA&quot;,&quot;SK vs SK+t-PA&quot;,
                              &quot;SK vs r-PA&quot;,&quot;SK vs TNK&quot;,&quot;SK vs PTCA&quot;,
                              &quot;t-PA vs Acc t-PA&quot;,&quot;t-PA vs SK+t-PA&quot;,
                              &quot;t-PA vs r-PA&quot;,&quot;t-PA vs TNK&quot;,&quot;t-PA vs PTCA&quot;,
                              &quot;Acc t-PA vs SK+t-PA&quot;,&quot;Acc t-PA vs r-PA&quot;,
                              &quot;Acc t-PA vs TNK&quot;,&quot;Acc t-PA vs PTCA&quot;,
                              &quot;SK+t-PA vs r-PA&quot;,&quot;SK+t-PA vs TNK&quot;,
                             &quot;SK+t-PA vs PTCA&quot;,&quot;r-PA vs TNK&quot;,&quot;r-PA vs PTCA&quot;,
                              &quot;TNK vs PTCA&quot;)) </code></pre>
<pre><code>## Warning: &#39;geom_halfeyeh&#39; is deprecated.
## Use &#39;stat_halfeye&#39; instead.
## See help(&quot;Deprecated&quot;) and help(&quot;tidybayes-deprecated&quot;).</code></pre>
<p><img src="how-to-meta2_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
</div>
<div id="間接効果による精度の向上" class="section level3">
<h3>間接効果による精度の向上</h3>
<p><a href="https://kunisatolab.github.io/main/how-to-meta1.html">一対比較のベイジアンメタ分析の結果</a>と比べた時，Acc t-PAに対するPTCAの相対効果について，一対比較とネットワークとで比較すると（下表），ネットワークのほうが効果がやや大きくなり（オッズ比が小さくなり），その確信区間が狭くなっていることが分かります。間接効果を含めることで，事後分布の幅が狭くなっており，精度が高くなっていることが分かります。</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>mean</th>
<th>se_mean</th>
<th>sd</th>
<th>2.5%</th>
<th>97.5%</th>
<th>n_eff</th>
<th>Rhat</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>一対比較</td>
<td>0.7967</td>
<td>0.0007</td>
<td>0.0954</td>
<td>0.6257</td>
<td>0.9974</td>
<td>17086</td>
<td>0.9999</td>
</tr>
<tr class="even">
<td>ネットワーク</td>
<td>0.7311</td>
<td>0.0005</td>
<td>0.0714</td>
<td>0.6010</td>
<td>0.8796</td>
<td>25052</td>
<td>1.0000</td>
</tr>
</tbody>
</table>
</div>
<div id="ランキング" class="section level3">
<h3>ランキング</h3>
<p>各治療のdが推定できましたので，これを使って，治療のランキングを作ります。サンプリングの結果生じたdのサンプルを使って，一回のサンプリングごとに治療のランキングを計算して，順位ごとに1か0の値を保存していきます。最終的にその平均値を計算することで各治療の順位の確率を計算します。コードが実に汎用性の低い＆冗長なものになっているので，良い案があれば，ご指摘いただけると嬉しいです。</p>
<pre class="r"><code>d &lt;- fit_fixed_net %&gt;%
  spread_draws(d[treatment]) %&gt;% 
  spread(treatment,d) %&gt;% 
  rename(
    d1 = `1`,d2 = `2`, d3 = `3`, d4 = `4`, d5 = `5`, d6 = `6`
  ) %&gt;% 
  mutate(d0 = 0)

calNum &lt;- length(d$d1)
d1_rank &lt;- matrix(0, nrow=calNum, ncol=7)
d2_rank &lt;- matrix(0, nrow=calNum, ncol=7)
d3_rank &lt;- matrix(0, nrow=calNum, ncol=7)
d4_rank &lt;- matrix(0, nrow=calNum, ncol=7)
d5_rank &lt;- matrix(0, nrow=calNum, ncol=7)
d6_rank &lt;- matrix(0, nrow=calNum, ncol=7)
d0_rank &lt;- matrix(0, nrow=calNum, ncol=7)
for(i in 1:calNum){
  rk_d1 &lt;- rank(as.matrix(d[i,4:10]))[1]
  rk_d2 &lt;- rank(as.matrix(d[i,4:10]))[2]
  rk_d3 &lt;- rank(as.matrix(d[i,4:10]))[3]
  rk_d4 &lt;- rank(as.matrix(d[i,4:10]))[4]
  rk_d5 &lt;- rank(as.matrix(d[i,4:10]))[5]
  rk_d6 &lt;- rank(as.matrix(d[i,4:10]))[6]
  rk_d0 &lt;- rank(as.matrix(d[i,4:10]))[7]
  d1_rank[i,rk_d1] &lt;- 1
  d2_rank[i,rk_d2] &lt;- 1
  d3_rank[i,rk_d3] &lt;- 1
  d4_rank[i,rk_d4] &lt;- 1
  d5_rank[i,rk_d5] &lt;- 1
  d6_rank[i,rk_d6] &lt;- 1
  d0_rank[i,rk_d0] &lt;- 1
}
d1_rank &lt;- as_data_frame(d1_rank)</code></pre>
<pre><code>## Warning: The `x` argument of `as_tibble.matrix()` must have unique column names if `.name_repair` is omitted as of tibble 2.0.0.
## Using compatibility `.name_repair`.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_warnings()` to see where this warning was generated.</code></pre>
<pre class="r"><code>d2_rank &lt;- as_data_frame(d2_rank)
d3_rank &lt;- as_data_frame(d3_rank)
d4_rank &lt;- as_data_frame(d4_rank)
d5_rank &lt;- as_data_frame(d5_rank)
d6_rank &lt;- as_data_frame(d6_rank)
d0_rank &lt;- as_data_frame(d0_rank)

# SKのランクのプロット
d0_rank_p &lt;- d0_rank %&gt;% 
  gather(key = rank, value = value) %&gt;% 
  group_by(rank) %&gt;% 
  summarise(mean = mean(value),sd = sd(value)) %&gt;%
  mutate(rank = 1:7) %&gt;% 
  ggplot(aes(rank,mean)) +
  geom_line() +
  geom_point()+
  scale_x_continuous(breaks=seq(1,7,by=1),limits=c(1,7)) +
  ylim(0,1) +
  labs(y=&quot;Probability&quot;, x=&quot;Rank of SK&quot;)</code></pre>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<pre class="r"><code># t-PAのランクのプロット
d1_rank_p &lt;- d1_rank %&gt;% 
  gather(key = rank, value = value) %&gt;% 
  group_by(rank) %&gt;% 
  summarise(mean = mean(value),sd = sd(value)) %&gt;%
  mutate(rank = 1:7) %&gt;% 
  ggplot(aes(rank,mean)) +
  geom_line() +
  geom_point()+
  scale_x_continuous(breaks=seq(1,7,by=1),limits=c(1,7)) +
  ylim(0,1) +
  labs(y=&quot;Probability&quot;, x=&quot;Rank of t-PA&quot;)</code></pre>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<pre class="r"><code># Acc t-PAのランクのプロット
d2_rank_p &lt;- d2_rank %&gt;% 
  gather(key = rank, value = value) %&gt;% 
  group_by(rank) %&gt;% 
  summarise(mean = mean(value),sd = sd(value)) %&gt;%
  mutate(rank = 1:7) %&gt;% 
  ggplot(aes(rank,mean)) +
  geom_line() +
  geom_point()+
  ylim(0,1) +
  labs(y=&quot;Probability&quot;, x=&quot;Rank of Acc t-PA&quot;)</code></pre>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<pre class="r"><code># SK t-PAのランクのプロット
d3_rank_p &lt;- d3_rank %&gt;% 
  gather(key = rank, value = value) %&gt;% 
  group_by(rank) %&gt;% 
  summarise(mean = mean(value),sd = sd(value)) %&gt;%
  mutate(rank = 1:7) %&gt;% 
  ggplot(aes(rank,mean)) +
  geom_line() +
  geom_point()+
  scale_x_continuous(breaks=seq(1,7,by=1),limits=c(1,7)) +
  ylim(0,1) +
  labs(y=&quot;Probability&quot;, x=&quot;Rank of SK t-PA&quot;)</code></pre>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<pre class="r"><code># r-PAのランクのプロット
d4_rank_p &lt;- d4_rank %&gt;% 
  gather(key = rank, value = value) %&gt;% 
  group_by(rank) %&gt;% 
  summarise(mean = mean(value),sd = sd(value)) %&gt;%
  mutate(rank = 1:7) %&gt;% 
  ggplot(aes(rank,mean)) +
  geom_line() +
  geom_point()+
  scale_x_continuous(breaks=seq(1,7,by=1),limits=c(1,7)) +
  ylim(0,1) +
  labs(y=&quot;Probability&quot;, x=&quot;Rank of r-PA&quot;)</code></pre>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<pre class="r"><code># TNKのランクのプロット
d5_rank_p &lt;- d5_rank %&gt;% 
  gather(key = rank, value = value) %&gt;% 
  group_by(rank) %&gt;% 
  summarise(mean = mean(value),sd = sd(value)) %&gt;%
  mutate(rank = 1:7) %&gt;% 
  ggplot(aes(rank,mean)) +
  geom_line() +
  geom_point()+
  scale_x_continuous(breaks=seq(1,7,by=1),limits=c(1,7)) +
  ylim(0,1) +
  labs(y=&quot;Probability&quot;, x=&quot;Rank of TNK&quot;)</code></pre>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<pre class="r"><code># PTCAのランクのプロット
d6_rank_p &lt;- d6_rank %&gt;% 
  gather(key = rank, value = value) %&gt;% 
  group_by(rank) %&gt;% 
  summarise(mean = mean(value),sd = sd(value)) %&gt;%
  mutate(rank = 1:7) %&gt;% 
  ggplot(aes(rank,mean)) +
  geom_line() +
  geom_point()+
  scale_x_continuous(breaks=seq(1,7,by=1),limits=c(1,7)) +
  ylim(0,1) +
  labs(y=&quot;Probability&quot;, x=&quot;Rank of PTCA&quot;)</code></pre>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<pre class="r"><code># プロットを並べる
grid.arrange(d0_rank_p, d1_rank_p, d2_rank_p, d3_rank_p, d4_rank_p, d5_rank_p,d6_rank_p,ncol = 2)</code></pre>
<p><img src="how-to-meta2_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>ランキングの結果からは，PTCAが１位というのが分かりますね。</p>
</div>
<div id="モデル比較" class="section level3">
<h3>モデル比較</h3>
<p>単体では意味がないですが，モデル比較をすることもあるかと思い，Stanコードでは対数尤度も計算をしています。以下のコードでWAICも算出できます。</p>
<pre class="r"><code>log_like &lt;- extract_log_lik(fit_fixed_net)
waic(log_like)</code></pre>
<pre><code>## Warning: 
## 34 (46.6%) p_waic estimates greater than 0.4. We recommend trying loo instead.</code></pre>
<pre><code>## 
## Computed from 20000 by 73 log-likelihood matrix
## 
##           Estimate   SE
## elpd_waic   -216.4  9.4
## p_waic        29.4  2.0
## waic         432.7 18.9
## 
## 34 (46.6%) p_waic estimates greater than 0.4. We recommend trying loo instead.</code></pre>
<p>これで，固定効果モデルのネットワークメタ分析をStanで実行できました！今回は，ネットワークメタ分析の推定だけを記事にしましたが，ネットワークメタ分析には，同質性，類似性，一貫性などの前提があります。その前提を確認する必要があります。</p>
</div>
</div>

<footer>
  <p>Copyright &copy; 2013-2020 Yoshihiko Kunisato. All rights reserved </p>
</footer>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
