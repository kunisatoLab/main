<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>強化学習モデル: ベイズ推定(1)</title>

<script src="site_libs/header-attrs-2.7/header-attrs.js"></script>
<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link rel="apple-touch-icon" type="image/png" href="apple-touch-icon-180x180.png">
<link rel="icon" type="image/png" href="icon-192x192.png">


<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>





<link rel="stylesheet" href="site_style.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-sm-12 col-md-4 col-lg-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-sm-12 col-md-8 col-lg-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Computational Clinical Psychology Lab</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="research.html">Research</a>
</li>
<li>
  <a href="team.html">Team</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Publications
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="book.html">書籍</a>
    </li>
    <li>
      <a href="articles.html">学術論文</a>
    </li>
    <li>
      <a href="articles-japanese.html">学術論文（日本語）</a>
    </li>
    <li>
      <a href="bulletin.html">紀要論文</a>
    </li>
    <li>
      <a href="presentation.html">国際会議発表</a>
    </li>
    <li>
      <a href="presentation-japanese.html">国内学会・研究会発表</a>
    </li>
  </ul>
</li>
<li>
  <a href="code_tips.html">Code &amp; Tips</a>
</li>
<li>
  <a href="education.html">Education</a>
</li>
<li>
  <a href="news.html">News</a>
</li>
<li>
  <a href="https://kunisatolab.github.io/english/index.html">English</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">強化学習モデル: ベイズ推定(1)</h1>

</div>


<div id="認知モデリングの推奨実践法" class="section level2">
<h2>認知モデリングの推奨実践法</h2>
<p>Busemeyer &amp; Diederich(2010), Heathcote (2014), Palminteri et al.(2017)を参考にまとめると，以下のような感じになります。</p>
<ul>
<li>A 認知課題と認知モデルを準備</li>
<li>B 人工データ生成とパラメータリカバリーを確認（モデルや課題の修正）</li>
<li>C データ収集と行動データを確認</li>
<li>D パラメータ推定</li>
<li>E 相対モデル比較</li>
<li>F モデル・シミュレーションと選択的影響テスト</li>
</ul>
<p><a href="https://kunisatolab.github.io/main/how-to-cognitive-modeling-rl1.html" target="_blank">「強化学習モデル: 最尤推定」</a>ではABCDとすすめてきました。今回は，ベイズ推定をcmdstanを使って行ってみます。そこで，一度Bに戻ってからDに取り組みます。</p>
<div id="使用するrパッケージ" class="section level3">
<h3>使用するRパッケージ</h3>
<p>適宜必要なパッケージをインストールしてください。cmdstnrのインストールは，<a href="https://mc-stan.org/cmdstanr/" target="_blank">こちら</a>をご確認ください。</p>
<pre class="r"><code>rm(list = ls())
library(tidyverse)
library(cmdstanr)
library(rstan)
library(posterior)
library(bridgesampling)</code></pre>
</div>
</div>
<div id="b-人工データ生成とパラメータリカバリーを確認モデルや課題の修正" class="section level2">
<h2>B 人工データ生成とパラメータリカバリーを確認（モデルや課題の修正）</h2>
<div id="人工データの生成" class="section level3">
<h3>人工データの生成</h3>
<p>改めて人工データを生成するために，実験状況の入ったsim_dataの準備とq_learning_sim関数とq_learning_ll関数の準備をします。</p>
<pre class="r"><code>sim_data &lt;- tibble(trial = 1:80,
                   prob_s1 = rep(c(0.2, 0.8), each = 40),
                   prob_s2 = rep(c(0.8, 0.2), each = 40),
                   reward_s1 = ifelse(runif(80) &lt; prob_s1, 1, 0),
                   reward_s2 = ifelse(runif(80) &lt; prob_s2, 1, 0))

q_learning_sim &lt;- function(alpha, beta,data) {
  #変数の準備
  value_s1 &lt;- 0          # s1の価値(初期値は0)
  value_s2 &lt;- 0          # s2の価値(初期値は0)
  current_choice &lt;- NULL     # ある時点の選択（1=s1，0=s2）
  choice_prob_s1 &lt;- NULL  # s1の選択確率
  reward &lt;- NULL                 # 報酬
  # Qlearningモデル
  for (i in 1:nrow(data)){
    # s1を選ぶ確率を計算し,一様分布から発生させた乱数が行動選択確率よりも小さい時に1（s1），大きい時に0（s2）
    choice_prob_s1[i] &lt;- exp(beta*value_s1[i])/(exp(beta*value_s1[i])+exp(beta*value_s2[i]))
    current_choice[i] &lt;- as.integer(runif(1,min=0,max=1) &lt;= choice_prob_s1[i])
    #FBを報酬(r)として、価値の更新を行う。
    if (current_choice[i] == 1){
        reward[i] &lt;- data$reward_s1[i]
        #予測誤差の計算
        prediction_error &lt;-  reward[i] - value_s1[i]
        #予測誤差を使ってs1の価値を更新する
        value_s1[i+1] &lt;- value_s1[i]+alpha*prediction_error
        #s2は更新なし
        value_s2[i+1] &lt;- value_s2[i]
    }else{
        reward[i] &lt;- data$reward_s2[i]
        #予測誤差の計算
        prediction_error &lt;- reward[i] - value_s2[i]
        #予測誤差を使ってs2の価値を更新する
        value_s2[i+1] &lt;- value_s2[i]+alpha*prediction_error
        #s1は更新なし
        value_s1[i+1] &lt;- value_s1[i]
    }
  }
  result &lt;- data.frame(trial = data$trial,
              value_s1 = value_s1[1:nrow(data)], 
              value_s2 = value_s2[1:nrow(data)], 
              prob_s1 = choice_prob_s1,
              choice = current_choice,
              reward = reward)
  return(result)
}

q_learning_ll &lt;- function(alpha, beta,data) {
  #変数の準備
  value_s1 &lt;- 0          # s1の価値(初期値は0)
  value_s2 &lt;- 0          # s2の価値(初期値は0)
  prob_s1 &lt;- NULL  # s1の選択確率
  ll &lt;- 0                 # 対数尤度
  # Qlearningモデル
  for (i in 1:nrow(data)){
    # s1を選ぶ確率を計算
    prob_s1[i] &lt;- exp(beta*value_s1[i])/(exp(beta*value_s1[i])+exp(beta*value_s2[i]))
    #FBを報酬(r)として、価値の更新を行う。
    if (data$choice[i] == 1){
        #予測誤差の計算
        prediction_error &lt;-  data$reward[i] - value_s1[i]
        #予測誤差を使ってs1の価値を更新する
        value_s1[i+1] &lt;- value_s1[i]+alpha*prediction_error
        #s2は更新なし
        value_s2[i+1] &lt;- value_s2[i]
        # 対数尤度の計算のために選択したs1を選ぶ確率の対数を加算
        ll &lt;- ll + log(prob_s1[i])
    }else{
        #予測誤差の計算
        prediction_error &lt;- data$reward[i] - value_s2[i]
        #予測誤差を使ってs2の価値を更新する
        value_s2[i+1] &lt;- value_s2[i]+alpha*prediction_error
        #s1は更新なし
        value_s1[i+1] &lt;- value_s1[i]
        # 対数尤度の計算のために選択したs2を選ぶ確率の対数を加算
        ll &lt;- ll + log(1-prob_s1[i])
    }
  }
  result &lt;- data.frame(trial = data$trial,
              value_s1 = value_s1[1:nrow(data)], 
              value_s2 = value_s2[1:nrow(data)], 
              prob_s1 = prob_s1,
              choice = data$choice,
              reward = data$reward)
  return(list(result = result, ll = ll))
}</code></pre>
<p>alpha = 0.3, beta = 2で，シミュレーション・データを生成します。</p>
<pre class="r"><code>set.seed(1234)
data_1 &lt;- q_learning_sim(alpha = 0.3, beta = 2, sim_data)</code></pre>
</div>
<div id="cmdstanrでの推定" class="section level3">
<h3>cmdstanrでの推定</h3>
<div id="stanコードの作成" class="section level4">
<h4>Stanコードの作成</h4>
<p>“q_learning.stan”というファイルを作成して，以下のコードを書き込みます。Stanは統計モデリング用のプラットフォームで，MCMCサンプリングによるベイズ推定，変分推定，最適化による最尤推定が可能です。Stanでは，data,parameters,modelのようにブロックごとに指定をして，書いていきます（この３つが最小限のブロック数かと思います）。dataブロックでは入力するデータについて記述します（型と範囲の指定が必要です）。parameterブロックでは，推定するパラメータについて記述します（型と範囲の指定が必要です）。modelブロックでは，データとパラメータを用いた生成モデルの記載をします。なお，データ~分布(y ~ normal(mu, sig))のような形で記述もできますし，target += 対数尤度のように，対数尤度でも記述ができます。以下は，Q学習の推定用のコードですが，グリッドサーチで用意したものに比べて，すっきりしているかと思います。</p>
<pre><code>data {
  int&lt;lower=1&gt; trial;
  int&lt;lower=1,upper=2&gt; choice[trial]; // 1 or 2
  int&lt;lower=0,upper=1&gt; reward[trial]; // 0 or 1
}
parameters {
  real&lt;lower=0.0,upper=1.0&gt; alpha; //学習率
  real&lt;lower=0.0&gt; beta;            //逆温度
}
model {
  //学習率と逆温度の事前分布の指定はしていないので，parametersで指定した範囲の無情報事前分布が使われる
  matrix[trial,2] Q;
  Q[1, 1] = 0;
  Q[1, 2] = 0;
  
  for ( t in 1:trial) {
    // 対数尤度を足す
    target += log(exp(beta*Q[t,choice[t]])/(exp(beta*Q[t,choice[t]])+exp(beta*Q[t,3-choice[t]])));
    
    if (t &lt; trial) {
      // 選択された選択肢のQ値の更新
      Q[t+1,choice[t]] = Q[t, choice[t]] + alpha * (reward[t] - Q[t, choice[t]]);
      // 選択されなかった選択肢は更新しない
      Q[t+1, 3- choice[t]] = Q[t, 3- choice[t]];
    }
  }
}</code></pre>
<p>Stanコードがstanファイルとして保存できたら，cmdstan_model()コンパイルします。Rは便利ですが計算は遅い言語なので，c++のような高速な計算が可能な言語にコンパイルをします。ちなみに，stanをRで使う場合は，Rstanを使うことが多かったのですが，最近は，cmdstanrが開発されており，こっちのほうがコンパイルもサンプリングも早いのでおすすめです。</p>
<pre><code>q_learning &lt;- cmdstan_model(&#39;q_learning.stan&#39;)</code></pre>
</div>
</div>
<div id="最尤推定" class="section level3">
<h3>最尤推定</h3>
<p>コンパイルができたら，最適化による最尤推定をしてみましょう。最尤推定は，<a href="https://kunisatolab.github.io/main/how-to-cognitive-modeling-rl1.html" target="_blank">「強化学習モデル: 最尤推定」 </a>でも見てきたように，optimやpsoなどのRパッケージでできますが，ここではstanで最尤推定値を推定します。コンパイルしたモデル$optimize()で推定ができます。</p>
<pre><code>mle_cmdstan &lt;- q_learning$optimize(
  data = list(trial = nrow(data_1),
              reward = data_1$reward,
              choice = data_1$choice + 1),
  seed = 123)
mle_cmdstan$summary()</code></pre>
</div>
<div id="パラメータリカバリ最尤推定" class="section level3">
<h3>パラメータリカバリ（最尤推定）</h3>
<p>stanのoptimizeを用いた最尤推定のパラメータリカバリをします。αは0.1から1の範囲で0.1刻み，βは0.5から5の範囲で0.5刻みでデータ生成とパラメータ推定を行います(つまり100個分チェックします)。</p>
<pre><code>alpha_true &lt;- NULL
beta_true &lt;- NULL
alpha_estimated &lt;- NULL
beta_estimated &lt;- NULL
beta_set &lt;- 0

for (i in 1:10) {
  alpha_set &lt;- 0
  beta_set = beta_set + 0.5
  for (j in 1:10) {
    alpha_set = alpha_set + 0.1
    #データ生成
    data_2 &lt;- q_learning_sim(alpha = alpha_set, beta = beta_set, sim_data)
    alpha_true[(i-1)*10 + j] &lt;- alpha_set
    beta_true[(i-1)*10 + j] &lt;- beta_set
    #パラメータ推定(推定がミスった時用にtryCatch関数を準備)
    tryCatch({
      q_learning_mle &lt;- q_learning$optimize(
      data = list(trial = nrow(data_2),
              reward = data_2$reward,
              choice = data_2$choice + 1),
      seed = 123)
      alpha_estimated[(i-1)*10 + j] &lt;- q_learning_mle$mle(&quot;alpha&quot;)
      beta_estimated[(i-1)*10 + j] &lt;- q_learning_mle$mle(&quot;beta&quot;)
    },error = function(e) {message(e)})
  }
}

parameter_recovery_mle &lt;- data.frame(alpha_true = alpha_true[1:length(alpha_estimated)],
                                     beta_true = beta_true[1:length(alpha_estimated)],
                                     alpha_estimated = alpha_estimated[1:length(alpha_estimated)],
                                     beta_estimated = beta_estimated[1:length(alpha_estimated)])</code></pre>
<div id="パラメータリカバリ最尤推定の確認" class="section level4">
<h4>パラメータリカバリ（最尤推定）の確認</h4>
<p>パラメータリカバリーのチェックをしましょう。散布図を書いて，真値（研究者がデータ生成時に設定した値）と推定された値が強い相関を示しているか確認します（データ生成時や推定時に確率的な変動が生じるので，完全一致はありません）。最尤推定だと，一部のパラメータは推定ミスをすることがあります。真値とはずれて，極端に大きなαの値(つまり１付近の値)や低いαの値が確認できます。ちょっと気になりますね。</p>
<pre class="r"><code>parameter_recovery_mle %&gt;% 
  ggplot(aes(x = alpha_true, y = alpha_estimated)) +
  geom_point()</code></pre>
<p><img src="how-to-cognitive-modeling-rl2_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>どうもβの推定値の中にとても大きな値になってしまったものがあるようです。βの最大値は制約をかけてないので，すごく大きくなることがあります。これも気になります。</p>
<pre class="r"><code>parameter_recovery_mle %&gt;% 
  ggplot(aes(x = beta_true, y = beta_estimated)) +
  geom_point()</code></pre>
<p><img src="how-to-cognitive-modeling-rl2_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>確認しにくいので，10以下の推定値のみをプロットして確認します。</p>
<pre class="r"><code>parameter_recovery_mle %&gt;%
  filter(beta_estimated &lt; 10) %&gt;% 
  ggplot(aes(x = beta_true, y = beta_estimated)) +
  geom_point()</code></pre>
<p><img src="how-to-cognitive-modeling-rl2_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
</div>
</div>
<div id="ベイズ推定" class="section level3">
<h3>ベイズ推定</h3>
<ul>
<li>今度は，MCMCを用いたベイズ推定をしてみましょう！最尤推定のときは，optimizeでしたが，今度は，sampleを使います。違う点としては，MCMCの連鎖（チェーン）の本数（chains 4本が良いと思います），MCMCの初期のあまり収束してい部分をどのくらい捨てるか(iter_warmup, モデルに依存するのでtrace plotを見てから判断するのが良いと思います）,MCMCサンプルの数(iter_sampling 多いほうが推定は安定しますが，時間がかかります)，　並列化で使用するコアの数（parallel_chains，MCMCのチェーンを４とした場合は，４がいいですが，お手持ちのパソコンのコア数に依存します）を指定する点です。</li>
</ul>
<pre><code>q_learning_mcmc &lt;- q_learning$sample(
  data = list(trial = nrow(data_1),
              reward = data_1$reward,
              choice = data_1$choice + 1),
  seed = 123,
  chains = 4,
  iter_warmup = 500,
  iter_sampling = 1000,
  parallel_chains = 4)</code></pre>
<p>結果の要約を確認してみましょう。</p>
<pre class="r"><code>q_learning_mcmc$summary()</code></pre>
<pre><code>## # A tibble: 3 x 10
##   variable    mean  median    sd   mad      q5     q95  rhat ess_bulk ess_tail
##   &lt;chr&gt;      &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;
## 1 lp__     -39.7   -39.4   1.11  0.772 -41.9   -38.7    1.00    1517.    1660.
## 2 alpha      0.335   0.318 0.115 0.107   0.181   0.557  1.00    1968.    1383.
## 3 beta       2.56    2.53  0.576 0.569   1.67    3.55   1.00    1882.    2052.</code></pre>
<p>以下はMCMCについての診断結果です。</p>
<pre class="r"><code>q_learning_mcmc$cmdstan_diagnose()</code></pre>
<pre><code>## Processing csv files: /tmp/Rtmpdwazpf/q_learning-202105180219-1-07d706.csv, /tmp/Rtmpdwazpf/q_learning-202105180219-2-07d706.csv, /tmp/Rtmpdwazpf/q_learning-202105180219-3-07d706.csv, /tmp/Rtmpdwazpf/q_learning-202105180219-4-07d706.csv
## 
## Checking sampler transitions treedepth.
## Treedepth satisfactory for all transitions.
## 
## Checking sampler transitions for divergences.
## No divergent transitions found.
## 
## Checking E-BFMI - sampler transitions HMC potential energy.
## E-BFMI satisfactory for all transitions.
## 
## Effective sample size satisfactory.
## 
## Split R-hat values satisfactory all parameters.
## 
## Processing complete, no problems detected.</code></pre>
<p>trace plot と事後分布をプロットしてみましょう。trace plotはMCMCのチェーンがきれいにまざっているか確認をしましょう。</p>
<pre class="r"><code># ggplotやtidyverseで扱いやすく処理する
mcmc_samples = as_draws_df(q_learning_mcmc$draws())
# alphaのtrace plot
mcmc_samples %&gt;%
  mutate(chain = as.factor(.chain)) %&gt;% 
  ggplot(aes(x = .iteration, y = alpha, group = .chain, color = chain)) +
  geom_line()</code></pre>
<p><img src="how-to-cognitive-modeling-rl2_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<pre class="r"><code># betaのtrace plot(ごく少数の大きな値でプロットできないので10以下に絞った)
mcmc_samples %&gt;%
  mutate(chain = as.factor(.chain)) %&gt;% 
  filter(beta &lt; 10) %&gt;% 
  ggplot(aes(x = .iteration, y = beta, group = .chain, color = chain)) +
  geom_line()</code></pre>
<p><img src="how-to-cognitive-modeling-rl2_files/figure-html/unnamed-chunk-13-2.png" width="672" /></p>
<pre class="r"><code># alphaの事後分布
mcmc_samples %&gt;% 
  ggplot() +
  geom_histogram(aes(x=alpha),binwidth = 0.01)</code></pre>
<p><img src="how-to-cognitive-modeling-rl2_files/figure-html/unnamed-chunk-13-3.png" width="672" /></p>
<pre class="r"><code># betaの事後分布（ごく少数の大きな値があるとプロットできないので6以下に絞った）
mcmc_samples %&gt;% 
  filter(beta &lt; 6) %&gt;% 
ggplot() +
  geom_histogram(aes(x=beta),binwidth = 0.1)</code></pre>
<p><img src="how-to-cognitive-modeling-rl2_files/figure-html/unnamed-chunk-13-4.png" width="672" /></p>
</div>
<div id="パラメータリカバリベイズ推定" class="section level3">
<h3>パラメータリカバリ（ベイズ推定）</h3>
<p>ベイズ推定でもパラメータリカバリをしてみましょう。ただ，これは結構計算に時間がかかると思います。</p>
<pre><code>alpha_true &lt;- NULL
beta_true &lt;- NULL
alpha_estimated &lt;- NULL
beta_estimated &lt;- NULL
beta_set &lt;- 0

for (i in 1:10) {
  alpha_set &lt;- 0
  beta_set = beta_set + 0.5
  for (j in 1:10) {
    alpha_set = alpha_set + 0.1
    #データ生成
    data_2 &lt;- q_learning_sim(alpha = alpha_set, beta = beta_set, sim_data)
    alpha_true[(i-1)*10 + j] &lt;- alpha_set
    beta_true[(i-1)*10 + j] &lt;- beta_set
    print(paste(&quot;進捗状況：&quot;,(i-1)*10 + j,&quot;/100&quot;))
    #パラメータ推定(推定がミスった時用にtryCatch関数を準備)
    tryCatch({
      q_learning_mcmc &lt;- q_learning$sample(
        data = list(trial = nrow(data_2),
                   reward = data_2$reward,
                   choice = data_2$choice + 1),
        seed = 123,
        chains = 4,
        iter_warmup = 500,
        iter_sampling = 1000,
        parallel_chains = 4)
      mcmc_samples = as_draws_df(q_learning_mcmc$draws())
      alpha_estimated[(i-1)*10 + j] &lt;- mean(mcmc_samples$alpha)
      beta_estimated[(i-1)*10 + j] &lt;- mean(mcmc_samples$beta)
    },error = function(e) {message(e)})
  }
}

parameter_recovery_mcmc &lt;- data.frame(alpha_true = alpha_true,
                                     beta_true = beta_true,
                                     alpha_estimated = alpha_estimated,
                                     beta_estimated = beta_estimated)</code></pre>
<div id="パラメータリカバリベイズ推定の確認" class="section level4">
<h4>パラメータリカバリ（ベイズ推定）の確認</h4>
<p>パラメータリカバリーのチェックをしましょう。散布図を書いて，真値（研究者がデータ生成時に設定した値）と推定された値が強い相関を示しているか確認します（データ生成時や推定時に確率的な変動が生じるので，完全一致はありません）。最尤推定と同様に，真値と結構ずれて低い推定値などがあって気になるところです。</p>
<pre class="r"><code>parameter_recovery_mcmc %&gt;% 
  ggplot(aes(x = alpha_true, y = alpha_estimated)) +
  geom_point()</code></pre>
<p><img src="how-to-cognitive-modeling-rl2_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>最尤推定同様に，βがすごく大きくなることがあるのは，気になるところです。</p>
<pre class="r"><code>parameter_recovery_mcmc %&gt;%
  ggplot(aes(x = beta_true, y = beta_estimated)) +
  geom_point()</code></pre>
<p><img src="how-to-cognitive-modeling-rl2_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
</div>
</div>
<div id="事前分布の活用" class="section level3">
<h3>事前分布の活用</h3>
<p>上記の最尤推定や無情報の事前分布の場合だと，ベータがとても大きな値になる点が気にかかるところです。そこで事前分布にも情報をもたせることにします。最尤推定にはないベイズ推定の特徴は，事前分布と尤度からパラメータの事後分布を推定する点です。例えば，逆転学習課題でのパタメータ推定において，おおよそパラメータの分布が分かっていると，それを事前分布に使って，推定を安定化させることができます。例えば，Kanen et al.(2019)では，学習率αはden Ouden et al.(2013)を参考にベータ分布を事前分布に用い，逆温度βはGershman(2016)を参考にガンマ分布を用いています（なお，Karen et al.(2019)で用いるのは逆温度ではなく報酬感受性ですが，意味は同じです）。</p>
<ul>
<li>学習率αは極端に０や１に近い値が推定されることがありますが，実際は0や１に近い値を取ることは稀であると考えられるので，den Ouden et al.(2013)が用いているベータ分布(beta(α = 1.2,β = 1.2))のような形状だと推定が安定するかもしれません。</li>
</ul>
<pre class="r"><code>alpha = seq(0,1, length=100)
plot(alpha, dbeta(alpha, 1.2, 1.2), ylab=&quot;density&quot;, type =&quot;l&quot;, col=4)</code></pre>
<p><img src="how-to-cognitive-modeling-rl2_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<ul>
<li>学習率βは極端に大きな値が推定されることがありますが，実際はあまりに大きな推定値は少ないですし，大きくてもその効果は地位ので，Gershman(2016)が用いているガンマ分布(gamma(α = 4.82,β = 0.88))のような形状だと，極端に大きな推定値を避けられるかもしれません。</li>
</ul>
<pre class="r"><code>beta = seq(0,15, length=500)
plot(beta, dgamma(beta, 4.82, 0.88), ylab=&quot;density&quot;, type =&quot;l&quot;, col=4)</code></pre>
<p><img src="how-to-cognitive-modeling-rl2_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
</div>
<div id="情報の有る事前分布を用いた場合のパラメータリカバリ" class="section level3">
<h3>情報の有る事前分布を用いた場合のパラメータリカバリ</h3>
<p>上記を踏まえて，αの事前分布にベータ分布，βの事前分布にガンマ分布を仮定したStanコードを書いて，q_learning_prior.stanという名前で保存します。</p>
<pre><code>data {
  int&lt;lower=1&gt; trial;
  int&lt;lower=1,upper=2&gt; choice[trial]; // 1 or 2
  int&lt;lower=0,upper=1&gt; reward[trial]; // 0 or 1
}
parameters {
  real&lt;lower=0.0,upper=1.0&gt; alpha; //学習率
  real&lt;lower=0.0&gt; beta;            //逆温度
}
model {
  matrix[trial,2] Q;
  Q[1, 1] = 0;
  Q[1, 2] = 0;
  
  //学習率の事前分布にベータ分布，逆温度の事前分布にガンマ分布
  alpha ~ beta(1.2, 1.2); 
  beta ~ gamma(4.82, 0.88);
  
  for ( t in 1:trial) {
    // 対数尤度を足す
    target += log(exp(beta*Q[t,choice[t]])/(exp(beta*Q[t,choice[t]])+exp(beta*Q[t,3-choice[t]])));
    
    if (t &lt; trial) {
      // 選択された選択肢のQ値の更新
      Q[t+1,choice[t]] = Q[t, choice[t]] + alpha * (reward[t] - Q[t, choice[t]]);
      // 選択されなかった選択肢は更新しない
      Q[t+1, 3- choice[t]] = Q[t, 3- choice[t]];
    }
  }
}</code></pre>
<p>q_learning_prior.stanを使って，パラメータリカバリを実施してみます。</p>
<p>まず，上記のモデルをコンパイルします。</p>
<pre><code>q_learning_prior &lt;- cmdstan_model(&#39;q_learning_prior.stan&#39;)</code></pre>
<p>まず，先程のdata_1で試してみます。</p>
<pre><code>q_learning_prior_mcmc &lt;- q_learning_prior$sample(
  data = list(trial = nrow(data_1),
              reward = data_1$reward,
              choice = data_1$choice + 1),
  seed = 123,
  chains = 4,
  iter_warmup = 500,
  iter_sampling = 1000,
  parallel_chains = 4)</code></pre>
<p>結果の要約を確認してみましょう。</p>
<pre class="r"><code>q_learning_prior_mcmc$summary()</code></pre>
<pre><code>## # A tibble: 3 x 10
##   variable    mean  median    sd   mad      q5     q95  rhat ess_bulk ess_tail
##   &lt;chr&gt;      &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;
## 1 lp__     -38.6   -38.2   1.13  0.750 -40.8   -37.5    1.00    1602.    1730.
## 2 alpha      0.327   0.310 0.109 0.103   0.184   0.525  1.00    1838.    1656.
## 3 beta       2.73    2.70  0.553 0.538   1.88    3.69   1.00    1887.    2107.</code></pre>
<p>以下はMCMCについての診断結果です。</p>
<pre class="r"><code>q_learning_prior_mcmc$cmdstan_diagnose()</code></pre>
<pre><code>## Processing csv files: /tmp/Rtmpdwazpf/q_learning_prior-202105180224-1-7b3b19.csv, /tmp/Rtmpdwazpf/q_learning_prior-202105180224-2-7b3b19.csv, /tmp/Rtmpdwazpf/q_learning_prior-202105180224-3-7b3b19.csv, /tmp/Rtmpdwazpf/q_learning_prior-202105180224-4-7b3b19.csv
## 
## Checking sampler transitions treedepth.
## Treedepth satisfactory for all transitions.
## 
## Checking sampler transitions for divergences.
## No divergent transitions found.
## 
## Checking E-BFMI - sampler transitions HMC potential energy.
## E-BFMI satisfactory for all transitions.
## 
## Effective sample size satisfactory.
## 
## Split R-hat values satisfactory all parameters.
## 
## Processing complete, no problems detected.</code></pre>
<p>それでは，先程と同じデータでパラメータリカバリーをしてみましょう！</p>
<pre><code>alpha_true &lt;- NULL
beta_true &lt;- NULL
alpha_estimated &lt;- NULL
beta_estimated &lt;- NULL
beta_set &lt;- 0

for (i in 1:10) {
  alpha_set &lt;- 0
  beta_set = beta_set + 0.5
  for (j in 1:10) {
    alpha_set = alpha_set + 0.1
    #データ生成
    data_2 &lt;- q_learning_sim(alpha = alpha_set, beta = beta_set, sim_data)
    alpha_true[(i-1)*10 + j] &lt;- alpha_set
    beta_true[(i-1)*10 + j] &lt;- beta_set
    print(paste(&quot;進捗状況：&quot;,(i-1)*10 + j,&quot;/100&quot;))
    #パラメータ推定(推定がミスった時用にtryCatch関数を準備)
    tryCatch({
      q_learning_prior_mcmc &lt;- q_learning_prior$sample(
        data = list(trial = nrow(data_2),
                   reward = data_2$reward,
                   choice = data_2$choice + 1),
        seed = 123,
        chains = 4,
        iter_warmup = 500,
        iter_sampling = 1000,
        parallel_chains = 4)
      mcmc_samples = as_draws_df(q_learning_prior_mcmc$draws())
      alpha_estimated[(i-1)*10 + j] &lt;- mean(mcmc_samples$alpha)
      beta_estimated[(i-1)*10 + j] &lt;- mean(mcmc_samples$beta)
    },error = function(e) {message(e)})
  }
}

parameter_recovery_prior_mcmc &lt;- data.frame(alpha_true = alpha_true,
                                     beta_true = beta_true,
                                     alpha_estimated = alpha_estimated,
                                     beta_estimated = beta_estimated)</code></pre>
<div id="有情報事前分布を用いた場合のパラメータリカバリの確認" class="section level4">
<h4>有情報事前分布を用いた場合のパラメータリカバリの確認</h4>
<p>いい感じにパラメータリカバリーできています。無情報事前分布のときのようにすごく大きなβが発生しなくなっています。</p>
<pre class="r"><code>parameter_recovery_prior_mcmc %&gt;% 
  ggplot(aes(x = alpha_true, y = alpha_estimated)) +
  geom_point()</code></pre>
<p><img src="how-to-cognitive-modeling-rl2_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<pre class="r"><code>parameter_recovery_prior_mcmc %&gt;%
  ggplot(aes(x = beta_true, y = beta_estimated)) +
  geom_point()</code></pre>
<p><img src="how-to-cognitive-modeling-rl2_files/figure-html/unnamed-chunk-24-2.png" width="672" /></p>
</div>
</div>
</div>
<div id="c-データ収集と行動データを確認" class="section level2">
<h2>C データ収集と行動データを確認</h2>
<p>「強化学習モデルを使ったモデル・フィッティング１」と同じデータを使います。以下のコードで５名分のlong形式のデータセットを準備します。</p>
<pre class="r"><code>setwd(&quot;data&quot;)
file_names &lt;- list.files()
setwd(&quot;..&quot;)
# 確認用の図を入れる場所を確保
plot_check &lt;- NULL
# データを入れる場所を確保
data_long &lt;- NULL
for (i in 1:length(file_names)) {
  # file_namesのi番目のデータを読み込んで,上記の処理をして，tmp_dataに格納
  tmp_data &lt;- read_csv(paste(&quot;data&quot;,file_names[i], sep = &quot;/&quot;)) %&gt;% 
    filter(trial_type == &quot;html-button-response&quot;) %&gt;% 
    mutate(id = rep(i,80),
           trial = 1:80, 
           s1_prob = rep(c(0.2,0.8),each = 40),
           reward = ifelse(button_pressed == 0, reward_s1, reward_s2)) %&gt;% 
    select(id, trial,choice=button_pressed, rt, reward, s1_prob,reward_s1, reward_s2)
  # データの保存
  data_long &lt;- rbind(data_long, tmp_data)
  
  # plot
  plot_check[[i]] &lt;- ggplot(tmp_data, aes(x = trial, y = s1_prob)) +
    geom_line() +
    geom_line(aes(x= trial, y = choice), colour = &#39;blue&#39;) +
    geom_point(aes(x = trial, y = reward),colour = &#39;red&#39;)
}</code></pre>
</div>
<div id="d-パラメータ推定" class="section level2">
<h2>D パラメータ推定</h2>
<div id="個人のパラメータ推定無情報事前分布" class="section level3">
<h3>個人のパラメータ推定（無情報事前分布）</h3>
<p>Sub01</p>
<pre><code>data_individual &lt;- data_long %&gt;% 
  filter(id == 1)

q_learning_mcmc &lt;- q_learning$sample(
        data = list(trial = nrow(data_individual),
                   reward = data_individual$reward,
                   choice = data_individual$choice + 1),
        seed = 123,
        chains = 4,
        iter_warmup = 500,
        iter_sampling = 1000,
        parallel_chains = 4)

q_learning_mcmc$summary()
q_learning_mcmc$cmdstan_diagnose()</code></pre>
<p>結果のプロット</p>
<pre class="r"><code>q_learning_mcmc &lt;- as_draws_df(q_learning_mcmc$draws())
# alphaのtrace plot
q_learning_mcmc %&gt;%
  mutate(chain = as.factor(.chain)) %&gt;% 
  ggplot(aes(x = .iteration, y = alpha, group = .chain, color = chain)) +
  geom_line()</code></pre>
<p><img src="how-to-cognitive-modeling-rl2_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<pre class="r"><code># betaのtrace plot
q_learning_mcmc %&gt;%
  mutate(chain = as.factor(.chain)) %&gt;% 
  filter(beta &lt; 1000) %&gt;% 
  ggplot(aes(x = .iteration, y = beta, group = .chain, color = chain)) +
  geom_line()</code></pre>
<p><img src="how-to-cognitive-modeling-rl2_files/figure-html/unnamed-chunk-27-2.png" width="672" /></p>
<pre class="r"><code># alphaの事後分布
q_learning_mcmc %&gt;% 
  ggplot() +
  geom_histogram(aes(x=alpha),binwidth = 0.01)</code></pre>
<p><img src="how-to-cognitive-modeling-rl2_files/figure-html/unnamed-chunk-27-3.png" width="672" /></p>
<pre class="r"><code># betaの事後分布
q_learning_mcmc %&gt;% 
  filter(beta &lt; 1000) %&gt;% 
ggplot() +
  geom_histogram(aes(x=beta),binwidth = 0.1)</code></pre>
<p><img src="how-to-cognitive-modeling-rl2_files/figure-html/unnamed-chunk-27-4.png" width="672" /></p>
<pre class="r"><code>q_values &lt;- q_learning_ll(mean(mcmc_samples$alpha),mean(mcmc_samples$beta),data_individual)</code></pre>
</div>
<div id="個人のパラメータ推定有情報事前分布" class="section level3">
<h3>個人のパラメータ推定（有情報事前分布）</h3>
<p>sub01</p>
<pre><code>data_individual &lt;- data_long %&gt;% 
  filter(id == 1)

q_learning_prior_mcmc &lt;- q_learning_prior$sample(
        data = list(trial = nrow(data_individual),
                   reward = data_individual$reward,
                   choice = data_individual$choice + 1),
        seed = 123,
        chains = 4,
        iter_warmup = 500,
        iter_sampling = 1000,
        parallel_chains = 4)

q_learning_prior_mcmc$summary()
q_learning_prior_mcmc$cmdstan_diagnose()</code></pre>
<p>結果のプロット</p>
<pre class="r"><code>q_learning_prior_mcmc &lt;- as_draws_df(q_learning_prior_mcmc$draws())
# alphaのtrace plot
q_learning_prior_mcmc %&gt;%
  mutate(chain = as.factor(.chain)) %&gt;% 
  ggplot(aes(x = .iteration, y = alpha, group = .chain, color = chain)) +
  geom_line()</code></pre>
<p><img src="how-to-cognitive-modeling-rl2_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
<pre class="r"><code># betaのtrace plot
q_learning_prior_mcmc %&gt;%
  mutate(chain = as.factor(.chain)) %&gt;% 
  ggplot(aes(x = .iteration, y = beta, group = .chain, color = chain)) +
  geom_line()</code></pre>
<p><img src="how-to-cognitive-modeling-rl2_files/figure-html/unnamed-chunk-29-2.png" width="672" /></p>
<pre class="r"><code># alphaの事後分布
q_learning_prior_mcmc %&gt;% 
  ggplot() +
  geom_histogram(aes(x=alpha),binwidth = 0.01)</code></pre>
<p><img src="how-to-cognitive-modeling-rl2_files/figure-html/unnamed-chunk-29-3.png" width="672" /></p>
<pre class="r"><code># betaの事後分布
q_learning_prior_mcmc %&gt;% 
ggplot() +
  geom_histogram(aes(x=beta),binwidth = 0.1)</code></pre>
<p><img src="how-to-cognitive-modeling-rl2_files/figure-html/unnamed-chunk-29-4.png" width="672" /></p>
<pre class="r"><code>q_values &lt;- q_learning_ll(mean(mcmc_samples$alpha),mean(mcmc_samples$beta),data_individual)</code></pre>
<p>sub01のトレースプロットや事後分布をみる限りでは，有情報事前分布の方が推定がうまくいっているように見えます。</p>
<p>さて，ここまでで，ベイズ推定が出来るようになりました。次は<a href="https://kunisatolab.github.io/main/how-to-cognitive-modeling-rl3.html" target="_blank">「強化学習モデル: ベイズ推定(2)」</a>で，モデル比較などに取り組みます。</p>
</div>
</div>
<div id="引用参考文献" class="section level2">
<h2>引用・参考文献</h2>
<ul>
<li>Busemeyer, J. R., &amp; Diederich, A. (2010). Cognitive Modeling. SAGE.</li>
<li>den Ouden, H. E. M., Daw, N. D., Fernandez, G., Elshout, J. A., Rijpkema, M., Hoogman, M., Franke, B., &amp; Cools, R. (2013). Dissociable effects of dopamine and serotonin on reversal learning. Neuron, 80(4), 1090–1100.</li>
<li>Gershman, S. J. (2016). Empirical priors for reinforcement learning models. Journal of Mathematical Psychology, 71, 1–6.</li>
<li>Heathcote, A., Brown, S. D., &amp; Wagenmakers, E.-J. (2015). An Introduction to Good Practices in Cognitive Modeling. In B. U. Forstmann &amp; E.-J. Wagenmakers (Eds.), An Introduction to Model-Based Cognitive Neuroscience (pp. 25–48). Springer New York.</li>
<li>Kanen, J. W., Ersche, K. D., Fineberg, N. A., Robbins, T. W., &amp; Cardinal, R. N. (2019). Computational modelling reveals contrasting effects on reinforcement learning and cognitive flexibility in stimulant use disorder and obsessive-compulsive disorder: remediating effects of dopaminergic D2/3 receptor agents. Psychopharmacology, 236(8), 2337–2358.</li>
<li>Palminteri, S., Wyart, V., &amp; Koechlin, E. (2017). The Importance of Falsification in Computational Cognitive Modeling. Trends in Cognitive Sciences, 21(6), 425–433.</li>
</ul>
</div>

<footer>
  <p>Copyright &copy; 2013-2020 Yoshihiko Kunisato. All rights reserved </p>
</footer>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
